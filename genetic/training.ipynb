{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "from genetic.common_types import Rule, ConditionType, OperatorType, ActionType\n",
    "from genetic.agent import GeneticAgent\n",
    "from genetic.game import Game\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pommerman.agents import PlayerAgent\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "if \"FitnessMax\" in creator.__dict__:\n",
    "    del creator.FitnessMax\n",
    "if \"Individual\" in creator.__dict__:\n",
    "    del creator.Individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 100\n",
    "MUTATION_RATE = 0.3\n",
    "CROSSOVER_RATE = 0.7\n",
    "MAX_GENERATIONS = 50\n",
    "\n",
    "custom_map = [\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],  # Border walls\n",
    "    [1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1],  # Player 0 starting area\n",
    "    [1, 0, 1, 2, 1, 2, 1, 2, 1, 0, 1],\n",
    "    [1, 0, 2, 0, 2, 0, 2, 0, 2, 0, 1],\n",
    "    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    [1, 0, 2, 0, 2, 0, 2, 0, 2, 0, 1],  # Middle row\n",
    "    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    [1, 0, 2, 0, 2, 0, 2, 0, 2, 0, 1],\n",
    "    [1, 0, 1, 2, 1, 2, 1, 2, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1],  # Player 3 starting area\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],  # Border walls\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_condition():\n",
    "    return random.choice(list(ConditionType))\n",
    "\n",
    "def random_operator():\n",
    "    return random.choice(list(OperatorType))\n",
    "\n",
    "def random_action():\n",
    "    return random.choice(list(ActionType))\n",
    "\n",
    "def create_random_rule():\n",
    "    num_conditions = random.choices([1, 2, 3], weights=[1, 2, 7], k=1)[0]\n",
    "    conditions = [random_condition() for _ in range(num_conditions)]\n",
    "    \n",
    "    num_operators = num_conditions - 1\n",
    "    operators = [random_operator() for _ in range(num_operators)]\n",
    "    \n",
    "    action = random_action()\n",
    "    \n",
    "    return Rule(conditions, operators, action)\n",
    "\n",
    "def create_individual(num_rules):\n",
    "    return [create_random_rule() for _ in range(num_rules)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"rule\", create_random_rule)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "                toolbox.rule, n=10)\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_rule(rule, indpb=0.7):\n",
    "    if random.random() < indpb:\n",
    "        # 50% chance to add a condition if there are less than 3\n",
    "        if len(rule.conditions) < 3 and random.random() < 0.5:\n",
    "            rule.conditions.append(random_condition())\n",
    "            if len(rule.conditions) > 1:\n",
    "                rule.operators.append(random_operator())\n",
    "        # 50% chance to remove a condition if there are more than 1\n",
    "        elif len(rule.conditions) > 1 and random.random() < 0.5:\n",
    "            idx = random.randint(0, len(rule.conditions) - 1)\n",
    "            rule.conditions.pop(idx)\n",
    "            if idx < len(rule.operators):\n",
    "                rule.operators.pop(idx)\n",
    "            else:\n",
    "                rule.operators.pop(-1)\n",
    "        # otherwise, replace a condition\n",
    "        else:\n",
    "            idx = random.randint(0, len(rule.conditions) - 1)\n",
    "            rule.conditions[idx] = random_condition()\n",
    "\n",
    "    for i in range(len(rule.operators)):\n",
    "        if random.random() < indpb:\n",
    "            rule.operators[i] = random_operator()\n",
    "            \n",
    "    if random.random() < indpb:\n",
    "        rule.action = random_action()\n",
    "        \n",
    "    return rule\n",
    "\n",
    "def mutate_individual(individual):\n",
    "    num_rules_to_mutate = max(1, int(len(individual) * 0.3))\n",
    "    rule_indices = random.sample(range(len(individual)), num_rules_to_mutate)\n",
    "\n",
    "    for i in rule_indices:\n",
    "        individual[i] = mutate_rule(individual[i], 0.7)\n",
    "\n",
    "    return individual,\n",
    "\n",
    "def crossover_individuals(ind1, ind2):\n",
    "    cxpoint1 = random.randint(0, len(ind1))\n",
    "    cxpoint2 = random.randint(0, len(ind1))\n",
    "    if cxpoint1 > cxpoint2:\n",
    "        cxpoint1, cxpoint2 = cxpoint2, cxpoint1\n",
    "        \n",
    "    ind1[cxpoint1:cxpoint2], ind2[cxpoint1:cxpoint2] = \\\n",
    "        ind2[cxpoint1:cxpoint2], ind1[cxpoint1:cxpoint2]\n",
    "            \n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tournament(tournament_data):\n",
    "    population, indices, custom_map = tournament_data\n",
    "    agents = [GeneticAgent(rules=population[index], individual_index=index) for index in indices]\n",
    "    # game = Game(agents, custom_map=custom_map)\n",
    "    game = Game(agents)\n",
    "    results = game.play_game(num_episodes=3, render_mode=None)\n",
    "    return results\n",
    "\n",
    "def evaluate_population_in_tournament(population):\n",
    "    fitness_scores = [0] * len(population)\n",
    "    num_tournaments = len(population) // 4\n",
    "    \n",
    "    tournament_data = []\n",
    "    for _ in range(num_tournaments):\n",
    "        competitors_indices = np.random.choice(len(population), 4, replace=False)\n",
    "        tournament_data.append((population, competitors_indices, custom_map))\n",
    "\n",
    "    processor_count = min(multiprocessing.cpu_count(), len(tournament_data))\n",
    "    with multiprocessing.Pool(processes=processor_count) as pool:\n",
    "        all_results = pool.map(evaluate_tournament, tournament_data)\n",
    "        \n",
    "    for result in all_results:\n",
    "        for episode_result in result:\n",
    "            agents = episode_result['agents']\n",
    "            total_steps = episode_result['total_steps']\n",
    "            for agent in agents:\n",
    "                agent_index = agent['individual_index']\n",
    "                \n",
    "                if agent['winner']:\n",
    "                    fitness_scores[agent_index] += 25\n",
    "\n",
    "                visited_tiles = len(agent['visited_tiles'])\n",
    "                fitness_scores[agent_index] += visited_tiles * 0.5\n",
    "                fitness_scores[agent_index] += agent['bombs_placed']\n",
    "                fitness_scores[agent_index] += agent['step_count'] / total_steps * 2\n",
    "\n",
    "                if visited_tiles < 10 and agent['bombs_placed'] < 2:\n",
    "                    fitness_scores[agent_index] -= 5\n",
    "                \n",
    "    return [(score,) for score in fitness_scores]\n",
    "        \n",
    "        \n",
    "def evaluate_individual(individual):\n",
    "    return (0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"mate\", crossover_individuals)\n",
    "toolbox.register(\"mutate\", mutate_individual)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=5)\n",
    "toolbox.register(\"evaluate\", evaluate_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution(n_gen=10, pop_size=40):\n",
    "    pop_size = (pop_size // 4) * 4\n",
    "    if pop_size < 4:\n",
    "        pop_size = 4\n",
    "    \n",
    "    print(f\"Starting evolution with population size: {pop_size}\")\n",
    "    \n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    \n",
    "    fitnesses = evaluate_population_in_tournament(pop)\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    hof = tools.HallOfFame(10)\n",
    "    \n",
    "    for gen in range(n_gen):\n",
    "        print(f\"Generation {gen + 1}/{n_gen}\")\n",
    "        \n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        \n",
    "        # Replace the worst individuals in the population with the best individuals from the hall of fame\n",
    "        if len(hof) > 0:\n",
    "            worst_individuals = tools.selWorst(offspring, len(hof))\n",
    "\n",
    "            for i, (worst, elite) in enumerate(zip(worst_individuals, hof)):\n",
    "                idx = offspring.index(worst)\n",
    "                offspring[idx] = toolbox.clone(elite)\n",
    "                \n",
    "        for i in range(0, len(offspring), 2):\n",
    "            if i + 1 < len(offspring):\n",
    "                if random.random() < CROSSOVER_RATE:\n",
    "                    toolbox.mate(offspring[i], offspring[i + 1])\n",
    "                    del offspring[i].fitness.values\n",
    "                    del offspring[i + 1].fitness.values\n",
    "\n",
    "        for i in range(len(offspring)):\n",
    "            if random.random() < MUTATION_RATE:\n",
    "                toolbox.mutate(offspring[i])\n",
    "                del offspring[i].fitness.values\n",
    "                \n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = evaluate_population_in_tournament(invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            \n",
    "        pop[:] = offspring\n",
    "        \n",
    "        hof.update(pop)\n",
    "        \n",
    "        fits = [ind.fitness.values[0] for ind in pop]\n",
    "        length = len(pop)\n",
    "        mean = sum(fits) / length\n",
    "        sum2 = sum(x*x for x in fits)\n",
    "        std = abs(sum2 / length - mean**2)**0.5\n",
    "        \n",
    "        print(f\"  Min: {np.min(fits)}\")\n",
    "        print(f\"  Max: {np.max(fits)}\")\n",
    "        print(f\"  Avg: {mean}\")\n",
    "        print(f\"  Best individual fitness: {hof[0].fitness.values[0]:.2f}\")\n",
    "\n",
    "        # Save current generation with pickle\n",
    "        # create a directory for generations if it doesn't exist\n",
    "\n",
    "        if gen % 5 == 0:\n",
    "            if not os.path.exists(\"generations\"):\n",
    "                os.makedirs(\"generations\")\n",
    "\n",
    "            with open(f\"generations/generation_{gen}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(pop, f)\n",
    "            with open(f\"generations/hof_{gen}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(hof, f)\n",
    "\n",
    "    return pop, stats, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evolution with population size: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/200\n",
      "  Min: -1.5\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 41.66033273325198\n",
      "  Best individual fitness: 354.48\n",
      "Generation 2/200\n",
      "  Min: -4.425\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 34.15316571752508\n",
      "  Best individual fitness: 354.48\n",
      "Generation 3/200\n",
      "  Min: -5.468181818181817\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 38.07656557390599\n",
      "  Best individual fitness: 354.48\n",
      "Generation 4/200\n",
      "  Min: -3.0\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 57.33724696813702\n",
      "  Best individual fitness: 354.48\n",
      "Generation 5/200\n",
      "  Min: -2.8875\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 63.733054320911734\n",
      "  Best individual fitness: 354.48\n",
      "Generation 6/200\n",
      "  Min: -1.5\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 65.72313934466708\n",
      "  Best individual fitness: 354.48\n",
      "Generation 7/200\n",
      "  Min: -1.5\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 61.51129003855565\n",
      "  Best individual fitness: 354.48\n",
      "Generation 8/200\n",
      "  Min: -1.5\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 73.14379343074826\n",
      "  Best individual fitness: 354.48\n",
      "Generation 9/200\n",
      "  Min: -2.283333333333333\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 79.29443815852204\n",
      "  Best individual fitness: 420.15\n",
      "Generation 10/200\n",
      "  Min: -1.5\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 74.60092686834813\n",
      "  Best individual fitness: 420.15\n",
      "Generation 11/200\n",
      "  Min: -1.94\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 87.85837710564402\n",
      "  Best individual fitness: 420.15\n",
      "Generation 12/200\n",
      "  Min: -1.5\n",
      "  Max: 354.47735597735596\n",
      "  Avg: 67.92155592424595\n",
      "  Best individual fitness: 420.15\n",
      "Generation 13/200\n",
      "  Min: -2.91\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 77.98117214544114\n",
      "  Best individual fitness: 420.15\n",
      "Generation 14/200\n",
      "  Min: 0.0\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 78.56352531854478\n",
      "  Best individual fitness: 420.15\n",
      "Generation 15/200\n",
      "  Min: 0.0\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 79.09382216438246\n",
      "  Best individual fitness: 420.15\n",
      "Generation 16/200\n",
      "  Min: -3.0\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 69.80718362150697\n",
      "  Best individual fitness: 420.15\n",
      "Generation 17/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 76.35918768913983\n",
      "  Best individual fitness: 420.15\n",
      "Generation 18/200\n",
      "  Min: -1.935\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 93.63271407689426\n",
      "  Best individual fitness: 420.15\n",
      "Generation 19/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 85.13568738059594\n",
      "  Best individual fitness: 420.15\n",
      "Generation 20/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 80.47096106936911\n",
      "  Best individual fitness: 420.15\n",
      "Generation 21/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 81.42781270535812\n",
      "  Best individual fitness: 420.15\n",
      "Generation 22/200\n",
      "  Min: -1.8550000000000004\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 78.09433201470416\n",
      "  Best individual fitness: 420.15\n",
      "Generation 23/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 75.38798632537905\n",
      "  Best individual fitness: 420.15\n",
      "Generation 24/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 73.17937016487467\n",
      "  Best individual fitness: 420.15\n",
      "Generation 25/200\n",
      "  Min: -1.521428571428571\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 89.8562150286199\n",
      "  Best individual fitness: 420.15\n",
      "Generation 26/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 74.11182041923966\n",
      "  Best individual fitness: 420.15\n",
      "Generation 27/200\n",
      "  Min: -1.9499999999999997\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 78.59998937266168\n",
      "  Best individual fitness: 420.15\n",
      "Generation 28/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 89.81205812146267\n",
      "  Best individual fitness: 420.15\n",
      "Generation 29/200\n",
      "  Min: -2.925\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 90.96321985111938\n",
      "  Best individual fitness: 420.15\n",
      "Generation 30/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 72.40777829350169\n",
      "  Best individual fitness: 420.15\n",
      "Generation 31/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 68.60170591214116\n",
      "  Best individual fitness: 420.15\n",
      "Generation 32/200\n",
      "  Min: -2.0804347826086955\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 68.32155436339677\n",
      "  Best individual fitness: 420.15\n",
      "Generation 33/200\n",
      "  Min: -2.9175000000000004\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 77.36716723490177\n",
      "  Best individual fitness: 420.15\n",
      "Generation 34/200\n",
      "  Min: -1.9250000000000003\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 76.92423783790927\n",
      "  Best individual fitness: 420.15\n",
      "Generation 35/200\n",
      "  Min: -0.9574999999999996\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 80.98805287683368\n",
      "  Best individual fitness: 420.15\n",
      "Generation 36/200\n",
      "  Min: -1.94\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 93.52944093531195\n",
      "  Best individual fitness: 420.15\n",
      "Generation 37/200\n",
      "  Min: -1.9450000000000003\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 65.63672613828108\n",
      "  Best individual fitness: 420.15\n",
      "Generation 38/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 66.21230974379101\n",
      "  Best individual fitness: 420.15\n",
      "Generation 39/200\n",
      "  Min: -1.9299999999999997\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 44.21854823140452\n",
      "  Best individual fitness: 420.15\n",
      "Generation 40/200\n",
      "  Min: -2.8199999999999994\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 42.59808181347639\n",
      "  Best individual fitness: 420.15\n",
      "Generation 41/200\n",
      "  Min: -3.0\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 74.34725160704426\n",
      "  Best individual fitness: 420.15\n",
      "Generation 42/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 62.61956019656261\n",
      "  Best individual fitness: 420.15\n",
      "Generation 43/200\n",
      "  Min: -2.925\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 81.06135427533879\n",
      "  Best individual fitness: 420.15\n",
      "Generation 44/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 92.10941761312836\n",
      "  Best individual fitness: 420.15\n",
      "Generation 45/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 97.92099195534854\n",
      "  Best individual fitness: 420.15\n",
      "Generation 46/200\n",
      "  Min: -3.4250000000000003\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 88.69646427303984\n",
      "  Best individual fitness: 420.15\n",
      "Generation 47/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 89.9803206492312\n",
      "  Best individual fitness: 420.15\n",
      "Generation 48/200\n",
      "  Min: -1.94\n",
      "  Max: 517.2272727272727\n",
      "  Avg: 96.77901818278147\n",
      "  Best individual fitness: 517.23\n",
      "Generation 49/200\n",
      "  Min: -1.9499999999999997\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 61.02163222010168\n",
      "  Best individual fitness: 517.23\n",
      "Generation 50/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 53.251994711562695\n",
      "  Best individual fitness: 517.23\n",
      "Generation 51/200\n",
      "  Min: -1.5\n",
      "  Max: 420.15336134453776\n",
      "  Avg: 53.60237565879587\n",
      "  Best individual fitness: 517.23\n",
      "Generation 52/200\n",
      "  Min: -2.1042857142857136\n",
      "  Max: 420.7724242424242\n",
      "  Avg: 66.66565813923816\n",
      "  Best individual fitness: 517.23\n",
      "Generation 53/200\n",
      "  Min: -1.6166666666666667\n",
      "  Max: 420.7724242424242\n",
      "  Avg: 70.01471741503583\n",
      "  Best individual fitness: 517.23\n",
      "Generation 54/200\n",
      "  Min: -3.0\n",
      "  Max: 420.7724242424242\n",
      "  Avg: 64.34151178940041\n",
      "  Best individual fitness: 517.23\n",
      "Generation 55/200\n",
      "  Min: -1.4249999999999998\n",
      "  Max: 517.2272727272727\n",
      "  Avg: 92.88473319790096\n",
      "  Best individual fitness: 517.23\n",
      "Generation 56/200\n",
      "  Min: -2.8949999999999996\n",
      "  Max: 517.2272727272727\n",
      "  Avg: 81.46267987382146\n",
      "  Best individual fitness: 517.23\n",
      "Generation 57/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 69.81704680721697\n",
      "  Best individual fitness: 520.37\n",
      "Generation 58/200\n",
      "  Min: -2.925\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 74.97206980894678\n",
      "  Best individual fitness: 520.37\n",
      "Generation 59/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 78.31792033642631\n",
      "  Best individual fitness: 520.37\n",
      "Generation 60/200\n",
      "  Min: -2.925\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 95.89981490816477\n",
      "  Best individual fitness: 520.37\n",
      "Generation 61/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 73.96669233724828\n",
      "  Best individual fitness: 520.37\n",
      "Generation 62/200\n",
      "  Min: -2.9175000000000004\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 67.07455258859594\n",
      "  Best individual fitness: 520.37\n",
      "Generation 63/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 57.74281393132932\n",
      "  Best individual fitness: 520.37\n",
      "Generation 64/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 84.29090029873258\n",
      "  Best individual fitness: 520.37\n",
      "Generation 65/200\n",
      "  Min: -2.925\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 74.09339966646007\n",
      "  Best individual fitness: 520.37\n",
      "Generation 66/200\n",
      "  Min: -2.925\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 64.49628004138178\n",
      "  Best individual fitness: 520.37\n",
      "Generation 67/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 59.56204290960736\n",
      "  Best individual fitness: 520.37\n",
      "Generation 68/200\n",
      "  Min: -2.925\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 70.17497860280818\n",
      "  Best individual fitness: 520.37\n",
      "Generation 69/200\n",
      "  Min: -2.4749999999999996\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 74.8071787332687\n",
      "  Best individual fitness: 520.37\n",
      "Generation 70/200\n",
      "  Min: -2.925\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 78.51046143180938\n",
      "  Best individual fitness: 520.37\n",
      "Generation 71/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 74.47069894265455\n",
      "  Best individual fitness: 520.37\n",
      "Generation 72/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 72.27316994140683\n",
      "  Best individual fitness: 520.37\n",
      "Generation 73/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 76.00706833773013\n",
      "  Best individual fitness: 520.37\n",
      "Generation 74/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 86.08141953888182\n",
      "  Best individual fitness: 520.37\n",
      "Generation 75/200\n",
      "  Min: -3.0\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 74.00035122578426\n",
      "  Best individual fitness: 520.37\n",
      "Generation 76/200\n",
      "  Min: -1.9450000000000003\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 64.12137751543099\n",
      "  Best individual fitness: 520.37\n",
      "Generation 77/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 72.68505263935593\n",
      "  Best individual fitness: 520.37\n",
      "Generation 78/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 73.06337621512705\n",
      "  Best individual fitness: 520.37\n",
      "Generation 79/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 70.19857933501387\n",
      "  Best individual fitness: 520.37\n",
      "Generation 80/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 78.76841113729941\n",
      "  Best individual fitness: 520.37\n",
      "Generation 81/200\n",
      "  Min: -3.3599999999999994\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 85.48977829551504\n",
      "  Best individual fitness: 520.37\n",
      "Generation 82/200\n",
      "  Min: -1.9499999999999997\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 94.24647751043629\n",
      "  Best individual fitness: 520.37\n",
      "Generation 83/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 76.38496629850795\n",
      "  Best individual fitness: 520.37\n",
      "Generation 84/200\n",
      "  Min: -1.9499999999999997\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 62.264542030718076\n",
      "  Best individual fitness: 547.74\n",
      "Generation 85/200\n",
      "  Min: -1.9499999999999997\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 74.26075150251522\n",
      "  Best individual fitness: 547.74\n",
      "Generation 86/200\n",
      "  Min: -2.4699999999999998\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 52.925602620883744\n",
      "  Best individual fitness: 547.74\n",
      "Generation 87/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 65.99717825685819\n",
      "  Best individual fitness: 547.74\n",
      "Generation 88/200\n",
      "  Min: -1.9450000000000003\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 83.69471134731155\n",
      "  Best individual fitness: 547.74\n",
      "Generation 89/200\n",
      "  Min: -2.925\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 78.91011756703519\n",
      "  Best individual fitness: 547.74\n",
      "Generation 90/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 99.64327680596811\n",
      "  Best individual fitness: 547.74\n",
      "Generation 91/200\n",
      "  Min: -3.8808974358974364\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 81.85259481547465\n",
      "  Best individual fitness: 547.74\n",
      "Generation 92/200\n",
      "  Min: -1.5\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 84.5546734783509\n",
      "  Best individual fitness: 547.74\n",
      "Generation 93/200\n",
      "  Min: -2.925\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 58.86913198092112\n",
      "  Best individual fitness: 547.74\n",
      "Generation 94/200\n",
      "  Min: -2.925\n",
      "  Max: 520.3701298701299\n",
      "  Avg: 50.234428626355495\n",
      "  Best individual fitness: 547.74\n",
      "Generation 95/200\n",
      "  Min: -3.0\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 62.87840173379004\n",
      "  Best individual fitness: 547.74\n",
      "Generation 96/200\n",
      "  Min: -2.811764705882352\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 63.545708289013994\n",
      "  Best individual fitness: 547.74\n",
      "Generation 97/200\n",
      "  Min: -1.4249999999999998\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 63.8666442565167\n",
      "  Best individual fitness: 547.74\n",
      "Generation 98/200\n",
      "  Min: -1.4175000000000004\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 71.7150547238711\n",
      "  Best individual fitness: 547.74\n",
      "Generation 99/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 76.84582875239742\n",
      "  Best individual fitness: 547.74\n",
      "Generation 100/200\n",
      "  Min: -2.4749999999999996\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 88.94909469735143\n",
      "  Best individual fitness: 547.74\n",
      "Generation 101/200\n",
      "  Min: -2.91\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 73.14461187626696\n",
      "  Best individual fitness: 547.74\n",
      "Generation 102/200\n",
      "  Min: -2.925\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 81.86156233094957\n",
      "  Best individual fitness: 547.74\n",
      "Generation 103/200\n",
      "  Min: -1.8275000000000006\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 75.89359088582272\n",
      "  Best individual fitness: 547.74\n",
      "Generation 104/200\n",
      "  Min: -1.6166666666666667\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 94.98474070465296\n",
      "  Best individual fitness: 547.74\n",
      "Generation 105/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 66.34412001587852\n",
      "  Best individual fitness: 547.74\n",
      "Generation 106/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 85.98452445916045\n",
      "  Best individual fitness: 547.74\n",
      "Generation 107/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 96.32564390579184\n",
      "  Best individual fitness: 547.74\n",
      "Generation 108/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 113.58572055514283\n",
      "  Best individual fitness: 547.74\n",
      "Generation 109/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 99.88634892297499\n",
      "  Best individual fitness: 547.74\n",
      "Generation 110/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 87.55576002488571\n",
      "  Best individual fitness: 547.74\n",
      "Generation 111/200\n",
      "  Min: -1.9450000000000003\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 101.24876842727042\n",
      "  Best individual fitness: 547.74\n",
      "Generation 112/200\n",
      "  Min: -3.435\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 124.15397130803791\n",
      "  Best individual fitness: 547.74\n",
      "Generation 113/200\n",
      "  Min: -1.9299999999999997\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 80.70850714250206\n",
      "  Best individual fitness: 547.74\n",
      "Generation 114/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 92.99972641737655\n",
      "  Best individual fitness: 547.74\n",
      "Generation 115/200\n",
      "  Min: -3.4450000000000003\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 81.29844185288619\n",
      "  Best individual fitness: 547.74\n",
      "Generation 116/200\n",
      "  Min: -4.949999999999999\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 82.98508014676794\n",
      "  Best individual fitness: 547.74\n",
      "Generation 117/200\n",
      "  Min: -4.395\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 58.66456632366402\n",
      "  Best individual fitness: 547.74\n",
      "Generation 118/200\n",
      "  Min: -2.925\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 68.7975832622912\n",
      "  Best individual fitness: 547.74\n",
      "Generation 119/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 63.18053440600482\n",
      "  Best individual fitness: 547.74\n",
      "Generation 120/200\n",
      "  Min: -2.385\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 49.890788156353935\n",
      "  Best individual fitness: 547.74\n",
      "Generation 121/200\n",
      "  Min: -1.9499999999999997\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 63.12733311199932\n",
      "  Best individual fitness: 547.74\n",
      "Generation 122/200\n",
      "  Min: -3.0\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 59.360088769260656\n",
      "  Best individual fitness: 547.74\n",
      "Generation 123/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 67.86719808961426\n",
      "  Best individual fitness: 547.74\n",
      "Generation 124/200\n",
      "  Min: -1.4249999999999998\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 72.35159405257616\n",
      "  Best individual fitness: 547.74\n",
      "Generation 125/200\n",
      "  Min: -1.9499999999999997\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 68.32734917872212\n",
      "  Best individual fitness: 547.74\n",
      "Generation 126/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 65.37489428066401\n",
      "  Best individual fitness: 547.74\n",
      "Generation 127/200\n",
      "  Min: -3.0\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 61.608839662671436\n",
      "  Best individual fitness: 547.74\n",
      "Generation 128/200\n",
      "  Min: -2.925\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 70.59254197881853\n",
      "  Best individual fitness: 547.74\n",
      "Generation 129/200\n",
      "  Min: -2.8424999999999994\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 71.6447150424767\n",
      "  Best individual fitness: 547.74\n",
      "Generation 130/200\n",
      "  Min: -2.925\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 59.86725727205701\n",
      "  Best individual fitness: 547.74\n",
      "Generation 131/200\n",
      "  Min: -2.1166666666666663\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 65.29120144751695\n",
      "  Best individual fitness: 547.74\n",
      "Generation 132/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 41.850396963743776\n",
      "  Best individual fitness: 547.74\n",
      "Generation 133/200\n",
      "  Min: -3.984883720930233\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 52.94399871734876\n",
      "  Best individual fitness: 547.74\n",
      "Generation 134/200\n",
      "  Min: -2.91\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 69.05544816088027\n",
      "  Best individual fitness: 547.74\n",
      "Generation 135/200\n",
      "  Min: -1.9450000000000003\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 92.03710206817406\n",
      "  Best individual fitness: 547.74\n",
      "Generation 136/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 106.57777398201449\n",
      "  Best individual fitness: 547.74\n",
      "Generation 137/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 89.36023967162762\n",
      "  Best individual fitness: 547.74\n",
      "Generation 138/200\n",
      "  Min: -4.4175\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 74.45324717632857\n",
      "  Best individual fitness: 547.74\n",
      "Generation 139/200\n",
      "  Min: -1.5\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 93.0881800853662\n",
      "  Best individual fitness: 547.74\n",
      "Generation 140/200\n",
      "  Min: -2.925\n",
      "  Max: 547.7380952380952\n",
      "  Avg: 102.97957654256768\n",
      "  Best individual fitness: 547.74\n",
      "Generation 141/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_pop, stats, hof \u001b[38;5;241m=\u001b[39m \u001b[43mrun_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvolution finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest individual has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(hof[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rules with fitness: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhof[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 48\u001b[0m, in \u001b[0;36mrun_evolution\u001b[0;34m(n_gen, pop_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m offspring[i]\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     47\u001b[0m invalid_ind \u001b[38;5;241m=\u001b[39m [ind \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m offspring \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ind\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalid]\n\u001b[0;32m---> 48\u001b[0m fitnesses \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_population_in_tournament\u001b[49m\u001b[43m(\u001b[49m\u001b[43minvalid_ind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind, fit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(invalid_ind, fitnesses):\n\u001b[1;32m     50\u001b[0m     ind\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m fit\n",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mevaluate_population_in_tournament\u001b[0;34m(population)\u001b[0m\n\u001b[1;32m     18\u001b[0m processor_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(multiprocessing\u001b[38;5;241m.\u001b[39mcpu_count(), \u001b[38;5;28mlen\u001b[39m(tournament_data))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mprocessor_count) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 20\u001b[0m     all_results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_tournament\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtournament_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_results:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m episode_result \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_pop, stats, hof = run_evolution(n_gen=200, pop_size=200)\n",
    "\n",
    "print(\"\\nEvolution finished.\")\n",
    "print(f\"Best individual has {len(hof[0])} rules with fitness: {hof[0].fitness.values[0]}\")\n",
    "print(\"Best individual rules:\")\n",
    "for rule in hof[0]:\n",
    "    print(rule)\n",
    "    \n",
    "with open(\"best_individual.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hof[0], f)\n",
    "    \n",
    "print(\"\\nBest individual saved to best_individual.pkl.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
