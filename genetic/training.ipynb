{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext line_profiler\n",
    "\n",
    "from typing import List\n",
    "import random\n",
    "from deap import base, creator, tools\n",
    "from pommerman.agents.simple_agent import SimpleAgent\n",
    "from genetic.common_types import Rule, Condition, ConditionType, OperatorType, ActionType\n",
    "from genetic.agent import GeneticAgent\n",
    "from genetic.game import Game\n",
    "import numpy as np\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import os\n",
    "import cProfile\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*pkg_resources.*\", category=UserWarning)\n",
    "\n",
    "if \"FitnessMax\" in creator.__dict__:\n",
    "    del creator.FitnessMax\n",
    "if \"Individual\" in creator.__dict__:\n",
    "    del creator.Individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 200\n",
    "MUTATION_RATE = 0.4\n",
    "MUTATION_RATE_RULE = 0.15\n",
    "MUTATION_RATE_REPLACE = 0.075\n",
    "MUTATION_RATE_SHUFFLE = 0.10\n",
    "MUTATION_RATE_ADD_COND = 0.05\n",
    "MUTATION_RATE_REMOVE_COND = 0.05\n",
    "MUTATION_RATE_REPLACE_COND = 0.3\n",
    "MUTATION_RATE_REPLACE_OPERATOR = 0.15\n",
    "MUTATION_RATE_REPLACE_ACTION = 0.15\n",
    "CROSSOVER_RATE = 0.75\n",
    "MAX_GENERATIONS = 200\n",
    "TOURNAMENT_SIZE = 7\n",
    "NUM_EPISODES = 2\n",
    "NUM_ELITES = POPULATION_SIZE // 20\n",
    "\n",
    "LOGGING_RESULTS = []\n",
    "LOGGING_CONDITIONS = []\n",
    "LOGGING_ACTIONS = []\n",
    "LOGGING_PERFORMANCE = []\n",
    "PREVIOUS_BEST = -1e6\n",
    "\n",
    "USEFUL_RULES = [\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_ON_PLAYER, False), Condition(ConditionType.CAN_MOVE_UP, False)], [OperatorType.AND], ActionType.MOVE_UP), 10),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_ON_PLAYER, False), Condition(ConditionType.CAN_MOVE_DOWN, False)], [OperatorType.AND], ActionType.MOVE_DOWN), 10),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_ON_PLAYER, False), Condition(ConditionType.CAN_MOVE_LEFT, False)], [OperatorType.AND], ActionType.MOVE_LEFT), 10),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_ON_PLAYER, False), Condition(ConditionType.CAN_MOVE_RIGHT, False)], [OperatorType.AND], ActionType.MOVE_RIGHT), 10),\n",
    "    (Rule([Condition(ConditionType.IS_WOOD_IN_RANGE, False), Condition(ConditionType.HAS_BOMB, False)], [OperatorType.AND], ActionType.PLACE_BOMB), 10),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_DOWN, False), Condition(ConditionType.CAN_MOVE_UP, False)], [OperatorType.AND], ActionType.MOVE_UP), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_DOWN, False), Condition(ConditionType.CAN_MOVE_LEFT, False)], [OperatorType.AND], ActionType.MOVE_LEFT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_DOWN, False), Condition(ConditionType.CAN_MOVE_RIGHT, False)], [OperatorType.AND], ActionType.MOVE_RIGHT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_UP, False), Condition(ConditionType.CAN_MOVE_DOWN, False)], [OperatorType.AND], ActionType.MOVE_DOWN), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_UP, False), Condition(ConditionType.CAN_MOVE_LEFT, False)], [OperatorType.AND], ActionType.MOVE_LEFT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_UP, False), Condition(ConditionType.CAN_MOVE_RIGHT, False)], [OperatorType.AND], ActionType.MOVE_RIGHT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_LEFT, False), Condition(ConditionType.CAN_MOVE_DOWN, False)], [OperatorType.AND], ActionType.MOVE_DOWN), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_LEFT, False), Condition(ConditionType.CAN_MOVE_UP, False)], [OperatorType.AND], ActionType.MOVE_UP), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_LEFT, False), Condition(ConditionType.CAN_MOVE_RIGHT, False)], [OperatorType.AND], ActionType.MOVE_RIGHT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_RIGHT, False), Condition(ConditionType.CAN_MOVE_DOWN, False)], [OperatorType.AND], ActionType.MOVE_DOWN), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_RIGHT, False), Condition(ConditionType.CAN_MOVE_UP, False)], [OperatorType.AND], ActionType.MOVE_UP), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_RIGHT, False), Condition(ConditionType.CAN_MOVE_LEFT, False)], [OperatorType.AND], ActionType.MOVE_LEFT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_ENEMY_IN_RANGE, False), Condition(ConditionType.HAS_BOMB, False)], [OperatorType.AND], ActionType.PLACE_BOMB), 10),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_condition():\n",
    "    condition_type = random.choice(list(ConditionType))\n",
    "    # negation = random.choices([True, False], weights=[0.25, 0.75], k=1)[0]\n",
    "    # negation = random.choices([True, False], weights=[0, 1], k=1)[0]\n",
    "    return Condition(condition_type, False)\n",
    "\n",
    "def random_operator():\n",
    "    return random.choice(list(OperatorType))\n",
    "\n",
    "def random_action():\n",
    "    return random.choice(list(ActionType))\n",
    "\n",
    "def create_random_rule():\n",
    "    num_conditions = random.choices([1, 2, 3], weights=[1, 3, 1], k=1)[0]\n",
    "    conditions = [random_condition() for _ in range(num_conditions)]\n",
    "    \n",
    "    num_operators = num_conditions - 1\n",
    "    operators = [random_operator() for _ in range(num_operators)]\n",
    "    \n",
    "    action = random_action()\n",
    "    \n",
    "    return Rule(conditions, operators, action)\n",
    "\n",
    "def create_individual(num_rules):\n",
    "    num_useful_rules = random.randint(1, 6)\n",
    "    # num_useful_rules = 0\n",
    "    \n",
    "    rules = [rule for rule, _ in USEFUL_RULES]\n",
    "    weights = [weight for _, weight in USEFUL_RULES]\n",
    "    indices = np.random.choice(\n",
    "        len(rules), \n",
    "        size=num_useful_rules,\n",
    "        replace=False,\n",
    "        p=np.array(weights) / sum(weights)\n",
    "    )\n",
    "    useful_sample = [rules[i] for i in indices]\n",
    "\n",
    "    random_rules = [create_random_rule() for _ in range(num_rules - num_useful_rules)]\n",
    "\n",
    "    rules = useful_sample + random_rules\n",
    "    \n",
    "    random.shuffle(rules)\n",
    "\n",
    "    individual = creator.Individual(rules)\n",
    "\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", create_individual, num_rules=10)\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_rule(rule: Rule):\n",
    "    # 50% chance to add a condition if there are less than 3\n",
    "    if len(rule.conditions) < 3 and random.random() < MUTATION_RATE_ADD_COND:\n",
    "        rule.conditions.append(random_condition())\n",
    "        if len(rule.conditions) > 1:\n",
    "            rule.operators.append(random_operator())\n",
    "\n",
    "    # 50% chance to remove a condition if there are more than 1\n",
    "    if len(rule.conditions) > 1 and random.random() < MUTATION_RATE_REMOVE_COND:\n",
    "        idx = random.randint(0, len(rule.conditions) - 1)\n",
    "        rule.conditions.pop(idx)\n",
    "        if idx < len(rule.operators):\n",
    "            rule.operators.pop(idx)\n",
    "        else:\n",
    "            rule.operators.pop(-1)\n",
    "\n",
    "    if len(rule.conditions) > 0 and random.random() < MUTATION_RATE_REPLACE_COND:\n",
    "        idx = random.randint(0, len(rule.conditions) - 1)\n",
    "        rule.conditions[idx] = random_condition()\n",
    "\n",
    "    # for i in range(len(rule.conditions)):\n",
    "    #     if random.random() < 0.1:\n",
    "    #         rule.conditions[i].negation = not rule.conditions[i].negation\n",
    "\n",
    "    for i in range(len(rule.operators)):\n",
    "        if random.random() < MUTATION_RATE_REPLACE_OPERATOR:\n",
    "            rule.operators[i] = random_operator()\n",
    "            \n",
    "    if random.random() < MUTATION_RATE_REPLACE_ACTION:\n",
    "        rule.action = random_action()\n",
    "        \n",
    "    return rule\n",
    "\n",
    "def mutate_individual(individual):\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < MUTATION_RATE_RULE:\n",
    "            if random.random() < MUTATION_RATE_REPLACE:\n",
    "                individual[i] = create_random_rule()\n",
    "            else:\n",
    "                individual[i] = mutate_rule(individual[i])\n",
    "\n",
    "    if random.random() < MUTATION_RATE_SHUFFLE:\n",
    "        return mutate_shuffle(individual)\n",
    "\n",
    "    return individual,\n",
    "\n",
    "def mutate_shuffle(individual):\n",
    "    if len(individual) < 2:\n",
    "        return individual,\n",
    "    \n",
    "    num_to_shuffle = random.randint(2, len(individual))\n",
    "    indices = random.sample(range(len(individual)), num_to_shuffle)\n",
    "    shuffled_rules = [individual[i] for i in indices]\n",
    "    \n",
    "    random.shuffle(shuffled_rules)\n",
    "    \n",
    "    temp_individual = list(individual)\n",
    "    for i, idx in enumerate(indices):\n",
    "        temp_individual[idx] = shuffled_rules[i]\n",
    "        \n",
    "    return temp_individual,\n",
    "\n",
    "def crossover_individuals(ind1, ind2):\n",
    "    cxpoint1 = random.randint(0, len(ind1) - 1)\n",
    "    cxpoint2 = random.randint(0, len(ind1) - 1)\n",
    "    if cxpoint1 > cxpoint2:\n",
    "        cxpoint1, cxpoint2 = cxpoint2, cxpoint1\n",
    "        \n",
    "    ind1[cxpoint1:cxpoint2], ind2[cxpoint1:cxpoint2] = \\\n",
    "        ind2[cxpoint1:cxpoint2], ind1[cxpoint1:cxpoint2]\n",
    "            \n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tournament(tournament_data):\n",
    "    population, indices = tournament_data\n",
    "    agents = [\n",
    "        GeneticAgent(\n",
    "            rules=population[index], \n",
    "            individual_index=index\n",
    "        ) for index in indices\n",
    "    ]\n",
    "    # agents.append(SimpleAgent())\n",
    "    # agents.append(SimpleAgent())\n",
    "\n",
    "    random.shuffle(agents)\n",
    "\n",
    "    game = Game(agents, max_steps=600)\n",
    "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
    "    return results\n",
    "\n",
    "def evaluate_population_in_tournament(population, generation, run_id):\n",
    "    fitness_scores = [0] * len(population)\n",
    "\n",
    "    agent_episode_counts = [0] * len(population)\n",
    "    \n",
    "    agents_per_tournament = 4\n",
    "    rounds_per_agent = 5\n",
    "\n",
    "    tournament_data = []\n",
    "    \n",
    "    for _ in range(rounds_per_agent):\n",
    "        shuffled_indices = list(range(len(population)))\n",
    "        random.shuffle(shuffled_indices)\n",
    "        \n",
    "        for i in range(0, len(shuffled_indices), agents_per_tournament):\n",
    "            current_indices = shuffled_indices[i:i + agents_per_tournament]\n",
    "            \n",
    "            if len(current_indices) == agents_per_tournament:\n",
    "                tournament_data.append((population, current_indices))\n",
    "    \n",
    "    processor_count = min(multiprocessing.cpu_count(), len(tournament_data))\n",
    "    with multiprocessing.Pool(processes=processor_count) as pool:\n",
    "        all_results = pool.map(evaluate_tournament, tournament_data)\n",
    "\n",
    "    rewards = {\n",
    "        \"TILES\": 15,             # Points per unique tile visited\n",
    "        \"BOMBS\": 75,            # Points per bomb placed\n",
    "        \"WOOD\": 150,             # Points per wood exploded\n",
    "        # \"DISTANCE\": 0.025,          # Points per unit distance from other agents\n",
    "        \"SELF_KILL\": -1000,       # Points for self-kill\n",
    "        \"KILL\": 750,            # Points for killing another agent\n",
    "        \"WIN_WITH_KILLS\": 1000,   # Points for winning with kills\n",
    "        \"WIN_NO_KILLS\": 200,     # Points for winning without kills\n",
    "        \"DIED\": -500,           # Points for dying\n",
    "        \"PASSIVE_TILES\": -50,        # Points for being passive (visited < 10 tiles)\n",
    "        \"PASSIVE_BOMBS\": -100,        # Points for being passive (placed < 4 bombs)\n",
    "        \"TIMEOUT_LOSE\": -150,    # Points for not winning or dying\n",
    "        \"STEP_REWARD\": 0.1, # Points per step taken\n",
    "        \"VISIT_PENALTY\": -5,     # Penalty per excess visit to frequently visited tiles\n",
    "    }\n",
    "\n",
    "    for result in all_results:\n",
    "        for episode_result in result:\n",
    "            agent_results = episode_result.agent_results\n",
    "            for agent_result in agent_results:\n",
    "                agent_episode_counts[agent_result.individual_index] += 1\n",
    "                agent_index = agent_result.individual_index\n",
    "                \n",
    "                visit_penalty = 0\n",
    "                # Calculate visit penalty for frequently visited tiles\n",
    "                for position, visit_count in agent_result.visited_tiles.items():\n",
    "                    if visit_count > 3:  # Penalty threshold\n",
    "                        excess_visits = visit_count - 3\n",
    "                        visit_penalty += excess_visits * rewards[\"VISIT_PENALTY\"]\n",
    "                unique_tiles_visited = len(agent_result.visited_tiles)\n",
    "            \n",
    "                logging_episode_result = {\n",
    "                    'generation': generation,\n",
    "                    'agent_index': agent_index,\n",
    "                    'episode_index': agent_episode_counts[agent_result.individual_index],\n",
    "                    'tiles': unique_tiles_visited * rewards[\"TILES\"],\n",
    "                    'bombs_placed': agent_result.bombs_placed * rewards[\"BOMBS\"],\n",
    "                    'wood_exploded': agent_result.wood_exploded * rewards[\"WOOD\"],\n",
    "                    'distance': 0,\n",
    "                    'self_kill': 0,\n",
    "                    'kills': 0,\n",
    "                    'win': 0,\n",
    "                    'alive': 0,\n",
    "                    'passive_tiles': 0,\n",
    "                    'passive_bombs': 0,\n",
    "                    'visit_penalty': visit_penalty,\n",
    "                    'fitness': 0,\n",
    "                    'step_reward': agent_result.step_count * rewards[\"STEP_REWARD\"],\n",
    "                    'steps': agent_result.step_count,\n",
    "                    'no_satisfied_rules': agent_result.no_satisfied_rules,\n",
    "                }\n",
    "\n",
    "                fitness = 0\n",
    "\n",
    "                fitness += unique_tiles_visited * rewards[\"TILES\"]\n",
    "                fitness += agent_result.bombs_placed * rewards[\"BOMBS\"]\n",
    "                fitness += agent_result.wood_exploded * rewards[\"WOOD\"]\n",
    "                fitness += agent_result.step_count * rewards[\"STEP_REWARD\"]\n",
    "                fitness += visit_penalty  # Add visit penalty to fitness\n",
    "\n",
    "                # In a 11x11 grid, the maximum distance is 20\n",
    "                # normalized_proximity_score = max(0, 20 - agent_result.average_distance)\n",
    "                # proximity_per_step = max(0, 20 - agent_result.average_distance)\n",
    "                # distance_score = proximity_per_step * agent_result.step_count * rewards[\"DISTANCE\"]\n",
    "                # fitness += distance_score\n",
    "                # logging_episode_result['distance'] += round(distance_score, 3)\n",
    "\n",
    "                for kill in agent_result.kills:\n",
    "                    if kill == agent_result.id:\n",
    "                        fitness += rewards[\"SELF_KILL\"]\n",
    "                        logging_episode_result['self_kill'] += rewards[\"SELF_KILL\"]\n",
    "                    else:\n",
    "                        fitness += rewards[\"KILL\"]\n",
    "                        logging_episode_result['kills'] += rewards[\"KILL\"]\n",
    "                        \n",
    "                if agent_result.winner:\n",
    "                    if len(agent_result.kills) > 0:\n",
    "                        fitness += rewards[\"WIN_WITH_KILLS\"]\n",
    "                        logging_episode_result['win'] += rewards[\"WIN_WITH_KILLS\"]\n",
    "                    else:\n",
    "                        fitness += rewards[\"WIN_NO_KILLS\"]\n",
    "                        logging_episode_result['win'] += rewards[\"WIN_NO_KILLS\"]\n",
    "                else:\n",
    "                    if not agent_result.is_alive:\n",
    "                        fitness += rewards[\"DIED\"]\n",
    "                        logging_episode_result['alive'] += rewards[\"DIED\"]\n",
    "                    else:\n",
    "                        fitness += rewards[\"TIMEOUT_LOSE\"]\n",
    "                        logging_episode_result['alive'] += rewards[\"TIMEOUT_LOSE\"]\n",
    "\n",
    "                if unique_tiles_visited < 10:\n",
    "                    tile_penalty = (10 - unique_tiles_visited) * rewards[\"PASSIVE_TILES\"]\n",
    "                    fitness += tile_penalty\n",
    "                    logging_episode_result['passive_tiles'] += tile_penalty\n",
    "                if agent_result.bombs_placed < 4:\n",
    "                    bomb_penalty = (4 - agent_result.bombs_placed) * rewards[\"PASSIVE_BOMBS\"]\n",
    "                    fitness += bomb_penalty\n",
    "                    logging_episode_result['passive_bombs'] += bomb_penalty\n",
    "\n",
    "                logging_episode_result['fitness'] = round(fitness, 3)\n",
    "                LOGGING_RESULTS.append(logging_episode_result)\n",
    "                \n",
    "                fitness_scores[agent_index] += fitness\n",
    "\n",
    "    # Normalize fitness scores\n",
    "    final_fitness_scores = [0.0] * len(fitness_scores)\n",
    "    for i in range(len(fitness_scores)):\n",
    "        if agent_episode_counts[i] > 0:\n",
    "            final_fitness_scores[i] = fitness_scores[i] / agent_episode_counts[i]\n",
    "        \n",
    "    return [(score,) for score in final_fitness_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"mate\", crossover_individuals)\n",
    "toolbox.register(\"mutate\", mutate_individual)\n",
    "toolbox.register(\"mutate_shuffle\", mutate_shuffle)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_structure(run_id):\n",
    "    if not os.path.exists('./results'):\n",
    "        os.makedirs('./results')\n",
    "    if not os.path.exists(f'./results/{run_id}'):\n",
    "        os.makedirs(f'./results/{run_id}')\n",
    "    if not os.path.exists(f'./results/{run_id}/best_individuals'):\n",
    "        os.makedirs(f'./results/{run_id}/best_individuals')\n",
    "        \n",
    "    LOGGING_RESULTS.clear()\n",
    "    LOGGING_CONDITIONS.clear()\n",
    "    LOGGING_ACTIONS.clear()\n",
    "    LOGGING_PERFORMANCE.clear()\n",
    "\n",
    "def get_performance_data(gen, pop, hof, run_id):\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    min = np.min(fits)\n",
    "    max = np.max(fits)\n",
    "    std = np.std(fits)\n",
    "    \n",
    "    best_fitness = hof[0].fitness.values[0]\n",
    "    global PREVIOUS_BEST\n",
    "    if best_fitness > PREVIOUS_BEST:\n",
    "        PREVIOUS_BEST = best_fitness\n",
    "        with open(f'./results/{run_id}/best_individuals/{gen}.txt', 'w') as f:\n",
    "            f.writelines([str(rule) + '\\n' for rule in hof[0]])\n",
    "\n",
    "    LOGGING_PERFORMANCE.append({\n",
    "        'generation': gen,\n",
    "        'mean': round(mean, 3),\n",
    "        'min': round(min, 3),\n",
    "        'max': round(max, 3),\n",
    "        'std': round(std, 3),\n",
    "        'best_fitness': round(best_fitness, 3),\n",
    "    })\n",
    "\n",
    "    return mean, min, max, std, best_fitness\n",
    "\n",
    "def get_conditions_actions_data(gen, pop: List[List[Rule]]):\n",
    "    pop_conditions = {\n",
    "        \"generation\": gen,\n",
    "    }\n",
    "    for condition in ConditionType:\n",
    "        for negation in [True, False]:\n",
    "            pop_conditions[(condition.name, negation)] = 0\n",
    "    pop_actions = {\n",
    "        \"generation\": gen,\n",
    "    }\n",
    "    for action in ActionType:\n",
    "        pop_actions[action] = 0\n",
    "\n",
    "    for individual in pop:\n",
    "        for rule in individual:\n",
    "            for condition in rule.conditions:\n",
    "                condition_key = (condition.condition_type.name, condition.negation)\n",
    "                pop_conditions[condition_key] += 1\n",
    "            pop_actions[rule.action] += 1\n",
    "            \n",
    "    LOGGING_CONDITIONS.append(pop_conditions)\n",
    "    LOGGING_ACTIONS.append(pop_actions)\n",
    "\n",
    "    return pop_conditions, pop_actions\n",
    "        \n",
    "def save_results(run_id, gen):\n",
    "    with open(f'./results/{run_id}/conditions.csv', 'a') as f:\n",
    "        fieldnames = LOGGING_CONDITIONS[0].keys()\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if gen == 0:\n",
    "            writer.writeheader()\n",
    "        for result in LOGGING_CONDITIONS:\n",
    "            writer.writerow(result)\n",
    "        \n",
    "    with open(f'./results/{run_id}/actions.csv', 'a') as f:\n",
    "        fieldnames = LOGGING_ACTIONS[0].keys()\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if gen == 0:\n",
    "            writer.writeheader()\n",
    "        for result in LOGGING_ACTIONS:\n",
    "            writer.writerow(result)\n",
    "\n",
    "    with open(f\"./results/{run_id}/agent_episodes.csv\", \"a\", newline='') as csvfile:\n",
    "        fieldnames = LOGGING_RESULTS[0].keys()\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if gen == 0:\n",
    "            writer.writeheader()\n",
    "        for result in LOGGING_RESULTS:\n",
    "            writer.writerow(result)\n",
    "\n",
    "    with open(f\"./results/{run_id}/performance.csv\", \"a\", newline='') as csvfile:\n",
    "        fieldnames = LOGGING_PERFORMANCE[0].keys()\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if gen == 0:\n",
    "            writer.writeheader()\n",
    "        for result in LOGGING_PERFORMANCE:\n",
    "            writer.writerow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution(n_gen=MAX_GENERATIONS, pop_size=POPULATION_SIZE, run_id=None):\n",
    "    create_folder_structure(run_id)\n",
    "\n",
    "    pop_size = (pop_size // 4) * 4\n",
    "    if pop_size < 4:\n",
    "        pop_size = 4\n",
    "    \n",
    "    print(f\"Starting evolution with population size: {pop_size}\")\n",
    "    \n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    \n",
    "    fitnesses = evaluate_population_in_tournament(pop, 0, run_id)\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    hof = tools.HallOfFame(2)\n",
    "    hof.update(pop)\n",
    "\n",
    "    get_performance_data(0, pop, hof, run_id)\n",
    "    get_conditions_actions_data(0, pop)\n",
    "\n",
    "    save_results(run_id, 0)\n",
    "    \n",
    "    for gen in range(1, n_gen + 1):\n",
    "        print(f\"Generation {gen}/{n_gen}\")\n",
    "        LOGGING_CONDITIONS.clear()\n",
    "        LOGGING_ACTIONS.clear()\n",
    "        LOGGING_PERFORMANCE.clear()\n",
    "        LOGGING_RESULTS.clear()\n",
    "\n",
    "        elites = tools.selBest(pop, NUM_ELITES)\n",
    "        elites = [toolbox.clone(ind) for ind in elites]\n",
    "        \n",
    "        offspring = toolbox.select(pop, len(pop) - NUM_ELITES)\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        \n",
    "        for i in range(0, len(offspring), 2):\n",
    "            if i + 1 < len(offspring):\n",
    "                if random.random() < CROSSOVER_RATE:\n",
    "                    toolbox.mate(offspring[i], offspring[i + 1])\n",
    "                    del offspring[i].fitness.values\n",
    "                    del offspring[i + 1].fitness.values\n",
    "\n",
    "        for i in range(len(offspring)):\n",
    "            if random.random() < MUTATION_RATE:\n",
    "                toolbox.mutate(offspring[i])\n",
    "                del offspring[i].fitness.values\n",
    "\n",
    "        pop[:] = offspring + elites\n",
    "\n",
    "        fitnesses = evaluate_population_in_tournament(pop, gen, run_id)\n",
    "        for ind, fit in zip(pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            \n",
    "        hof.update(pop)\n",
    "        \n",
    "        mean, min, max, std, best_fitness = get_performance_data(gen, pop, hof, run_id)\n",
    "        \n",
    "        print(f\"  Avg: {round(mean, 3)}\")\n",
    "        print(f\"  Min: {round(min, 3)}\")\n",
    "        print(f\"  Max: {round(max, 3)}\")\n",
    "        print(f\"  Std: {round(std, 3)}\")\n",
    "        print(f\"  Best individual fitness: {round(best_fitness, 3)}\")\n",
    "\n",
    "        get_conditions_actions_data(gen, pop)\n",
    "\n",
    "        with open(f'./results/{run_id}/best_individual.pkl', 'wb') as f:\n",
    "            pickle.dump(hof[0], f)\n",
    "\n",
    "        save_results(run_id, gen)\n",
    "\n",
    "    return pop, stats, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 51042\n",
      "Starting evolution with population size: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1709:\n",
      "Process ForkPoolWorker-1713:\n",
      "Process ForkPoolWorker-1705:\n",
      "Process ForkPoolWorker-1712:\n",
      "Process ForkPoolWorker-1707:\n",
      "Process ForkPoolWorker-1706:\n",
      "Process ForkPoolWorker-1708:\n",
      "Process ForkPoolWorker-1716:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m RUN_ID \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100000\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRUN_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m final_pop, stats, hof \u001b[38;5;241m=\u001b[39m \u001b[43mrun_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_GENERATIONS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPOPULATION_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRUN_ID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest agent in final population:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# sort final population by fitness\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[54], line 56\u001b[0m, in \u001b[0;36mrun_evolution\u001b[0;34m(n_gen, pop_size, run_id)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m offspring[i]\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     54\u001b[0m pop[:] \u001b[38;5;241m=\u001b[39m offspring \u001b[38;5;241m+\u001b[39m elites\n\u001b[0;32m---> 56\u001b[0m fitnesses \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_population_in_tournament\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind, fit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pop, fitnesses):\n\u001b[1;32m     58\u001b[0m     ind\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m fit\n",
      "Cell \u001b[0;32mIn[51], line 40\u001b[0m, in \u001b[0;36mevaluate_population_in_tournament\u001b[0;34m(population, generation, run_id)\u001b[0m\n\u001b[1;32m     38\u001b[0m processor_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(multiprocessing\u001b[38;5;241m.\u001b[39mcpu_count(), \u001b[38;5;28mlen\u001b[39m(tournament_data))\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mprocessor_count) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 40\u001b[0m     all_results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_tournament\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtournament_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m rewards \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTILES\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m15\u001b[39m,             \u001b[38;5;66;03m# Points per unique tile visited\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBOMBS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m75\u001b[39m,            \u001b[38;5;66;03m# Points per bomb placed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVISIT_PENALTY\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m,     \u001b[38;5;66;03m# Penalty per excess visit to frequently visited tiles\u001b[39;00m\n\u001b[1;32m     57\u001b[0m }\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_results:\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-1715:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-1714:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 73, in play_game\n",
      "    actions = self.env.act(state)\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 73, in play_game\n",
      "    actions = self.env.act(state)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 79, in play_game\n",
      "    state, reward, done, info = self.env.step(actions)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 73, in play_game\n",
      "    actions = self.env.act(state)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 79, in play_game\n",
      "    state, reward, done, info = self.env.step(actions)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 73, in play_game\n",
      "    actions = self.env.act(state)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 137, in act\n",
      "    return self.model.act(agents, obs, self.action_space)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 203, in step\n",
      "    obs = self.get_observations()\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 137, in act\n",
      "    return self.model.act(agents, obs, self.action_space)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 137, in act\n",
      "    return self.model.act(agents, obs, self.action_space)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 73, in play_game\n",
      "    actions = self.env.act(state)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 189, in step\n",
      "    result = self.model.step(\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 122, in act\n",
      "    ret.append(act_ex_communication(agent))\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 73, in play_game\n",
      "    actions = self.env.act(state)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 137, in act\n",
      "    return self.model.act(agents, obs, self.action_space)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 140, in get_observations\n",
      "    self.observations = self.model.get_observations(\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 122, in act\n",
      "    ret.append(act_ex_communication(agent))\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 122, in act\n",
      "    ret.append(act_ex_communication(agent))\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 101, in act_ex_communication\n",
      "    return agent.act(obs[agent.agent_id], action_space=action_space)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 430, in step\n",
      "    exploded_map = np.zeros_like(curr_board)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 137, in act\n",
      "    return self.model.act(agents, obs, self.action_space)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 76, in play_game\n",
      "    self._get_active_bombs(state)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 101, in act_ex_communication\n",
      "    return agent.act(obs[agent.agent_id], action_space=action_space)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 122, in act\n",
      "    ret.append(act_ex_communication(agent))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 566, in get_observations\n",
      "    assert hasattr(agent, attr)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 101, in act_ex_communication\n",
      "    return agent.act(obs[agent.agent_id], action_space=action_space)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 137, in act\n",
      "    return self.model.act(agents, obs, self.action_space)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 122, in act\n",
      "    ret.append(act_ex_communication(agent))\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 118, in _get_active_bombs\n",
      "    current_bombs = np.argwhere(bomb_mask)\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 42, in act\n",
      "    action = self.evaluate(obs, processed_board)\n",
      "  File \"<__array_function__ internals>\", line 200, in zeros_like\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 73, in play_game\n",
      "    actions = self.env.act(state)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/agents/base_agent.py\", line 14, in __getattr__\n",
      "    def __getattr__(self, attr):\n",
      "  File \"<__array_function__ internals>\", line 200, in argwhere\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 101, in act_ex_communication\n",
      "    return agent.act(obs[agent.agent_id], action_space=action_space)\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 42, in act\n",
      "    action = self.evaluate(obs, processed_board)\n",
      "  File \"/home/main/genetic-bomberman/venv/lib/python3.10/site-packages/numpy/core/numeric.py\", line 141, in zeros_like\n",
      "    z = zeros(1, dtype=res.dtype)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 108, in evaluate\n",
      "    result = self.evaluate_condition(obs, processed_board, condition)\n",
      "  File \"/home/main/genetic-bomberman/venv/lib/python3.10/site-packages/numpy/core/numeric.py\", line 625, in argwhere\n",
      "    return transpose(nonzero(a))\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 122, in act\n",
      "    ret.append(act_ex_communication(agent))\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 101, in act_ex_communication\n",
      "    return agent.act(obs[agent.agent_id], action_space=action_space)\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 42, in act\n",
      "    action = self.evaluate(obs, processed_board)\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 40, in act\n",
      "    self._distance_to_enemies(obs, processed_board)\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 108, in evaluate\n",
      "    result = self.evaluate_condition(obs, processed_board, condition)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 137, in act\n",
      "    return self.model.act(agents, obs, self.action_space)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 368, in _distance_to_enemies\n",
      "    average_distance = np.mean(distances)\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 108, in evaluate\n",
      "    result = self.evaluate_condition(obs, processed_board, condition)\n",
      "Process ForkPoolWorker-1711:\n",
      "Process ForkPoolWorker-1710:\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 158, in evaluate_condition\n",
      "    result = self._is_wood_in_range(obs, processed_board)\n",
      "  File \"<__array_function__ internals>\", line 200, in nonzero\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 42, in act\n",
      "    action = self.evaluate(obs, processed_board)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 101, in act_ex_communication\n",
      "    return agent.act(obs[agent.agent_id], action_space=action_space)\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 160, in evaluate_condition\n",
      "    result = self._can_move(obs, Direction.UP)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 122, in act\n",
      "    ret.append(act_ex_communication(agent))\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 275, in _is_wood_in_range\n",
      "    if board[new_y, new_x] == constants.Item.Wood.value:\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 127, in evaluate\n",
      "    current_condition_values.pop(i + 1)\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 146, in evaluate_condition\n",
      "    def evaluate_condition(self, obs: PommermanBoard, processed_board: ProcessedBoard, condition: Condition) -> bool:\n",
      "  File \"<__array_function__ internals>\", line 200, in mean\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 38, in act\n",
      "    processed_board = self.process_board(obs)\n",
      "  File \"/home/main/genetic-bomberman/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 1984, in nonzero\n",
      "    return _wrapfunc(a, 'nonzero')\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 101, in act_ex_communication\n",
      "    return agent.act(obs[agent.agent_id], action_space=action_space)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 200, in _can_move\n",
      "    if board[new_y, new_x] == constants.Item.Passage.value:\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 71, in process_board\n",
      "    enemy_mask |= (board == enemy_object.value)\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 38, in act\n",
      "    processed_board = self.process_board(obs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/main/genetic-bomberman/genetic/agent.py\", line 72, in process_board\n",
      "    enemy_positions = np.argwhere(enemy_mask)\n",
      "  File \"/home/main/genetic-bomberman/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 52, in _wrapfunc\n",
      "    bound = getattr(obj, method, None)\n",
      "  File \"<__array_function__ internals>\", line 180, in argwhere\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/main/genetic-bomberman/venv/lib/python3.10/site-packages/numpy/core/numeric.py\", line 574, in _argwhere_dispatcher\n",
      "    def _argwhere_dispatcher(a):\n",
      "  File \"/home/main/genetic-bomberman/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py\", line 3464, in mean\n",
      "    return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/main/genetic-bomberman/venv/lib/python3.10/site-packages/numpy/core/_methods.py\", line 175, in _mean\n",
      "    if issubclass(arr.dtype.type, (nt.integer, nt.bool_)):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "KeyboardInterrupt\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 79, in play_game\n",
      "    state, reward, done, info = self.env.step(actions)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 189, in step\n",
      "    result = self.model.step(\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 473, in step\n",
      "    flame_positions = np.where(exploded_map == 1)\n",
      "  File \"<__array_function__ internals>\", line 180, in where\n",
      "  File \"/home/main/genetic-bomberman/venv/lib/python3.10/site-packages/numpy/core/multiarray.py\", line 345, in where\n",
      "    @array_function_from_c_func_and_dispatcher(_multiarray_umath.where)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/tmp/ipykernel_7570/1714431743.py\", line 15, in evaluate_tournament\n",
      "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
      "  File \"/home/main/genetic-bomberman/genetic/game.py\", line 79, in play_game\n",
      "    state, reward, done, info = self.env.step(actions)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/envs/v0.py\", line 189, in step\n",
      "    result = self.model.step(\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/forward_model.py\", line 484, in step\n",
      "    curr_board[agent.position] = utility.agent_value(agent.agent_id)\n",
      "  File \"/home/main/genetic-bomberman/playground/pommerman/agents/base_agent.py\", line 14, in __getattr__\n",
      "    def __getattr__(self, attr):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# import pstats\n",
    "# import io\n",
    "\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    "\n",
    "RUN_ID = np.random.randint(0, 100000)\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "final_pop, stats, hof = run_evolution(n_gen=MAX_GENERATIONS, pop_size=POPULATION_SIZE, run_id=RUN_ID)\n",
    "\n",
    "print(\"Best agent in final population:\")\n",
    "# sort final population by fitness\n",
    "final_pop.sort(key=lambda ind: ind.fitness.values[0], reverse=True)\n",
    "print(f\"Best individual fitness: {final_pop[0].fitness.values[0]}\")\n",
    "print(f\"Best individual has {len(final_pop[0])} rules:\")\n",
    "for rule in final_pop[0]:\n",
    "    print(rule)\n",
    "\n",
    "print(\"\\nEvolution finished.\")\n",
    "print(f\"Stored best individual in ./results/{RUN_ID}/best_individual.pkl\")\n",
    "print(f\"Best individual has {len(hof[0])} rules with fitness: {hof[0].fitness.values[0]}\")\n",
    "print(\"Best individual rules:\")\n",
    "for rule in hof[0]:\n",
    "    print(rule)\n",
    "\n",
    "# pr.disable()\n",
    "# s = io.StringIO()\n",
    "# ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')\n",
    "# ps.print_stats(15)\n",
    "# print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f GeneticAgent.act run_evolution(n_gen=1, pop_size=20, run_id=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
