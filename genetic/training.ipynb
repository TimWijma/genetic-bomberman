{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import error GL! You will not be able to render --> Library \"GLU\" not found.\n"
     ]
    }
   ],
   "source": [
    "# %load_ext line_profiler\n",
    "\n",
    "from typing import List\n",
    "import random\n",
    "from deap import base, creator, tools\n",
    "from pommerman.agents.simple_agent import SimpleAgent\n",
    "from genetic.common_types import Rule, Condition, ConditionType, OperatorType, ActionType\n",
    "from genetic.agent import GeneticAgent\n",
    "from genetic.game import Game\n",
    "import numpy as np\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import os\n",
    "import cProfile\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*pkg_resources.*\", category=UserWarning)\n",
    "\n",
    "if \"FitnessMax\" in creator.__dict__:\n",
    "    del creator.FitnessMax\n",
    "if \"Individual\" in creator.__dict__:\n",
    "    del creator.Individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 200\n",
    "MUTATION_RATE = 0.4\n",
    "MUTATION_RATE_RULE = 0.15\n",
    "MUTATION_RATE_REPLACE = 0.075\n",
    "MUTATION_RATE_SHUFFLE = 0.10\n",
    "MUTATION_RATE_ADD_COND = 0.05\n",
    "MUTATION_RATE_REMOVE_COND = 0.05\n",
    "MUTATION_RATE_REPLACE_COND = 0.3\n",
    "MUTATION_RATE_REPLACE_OPERATOR = 0.15\n",
    "MUTATION_RATE_REPLACE_ACTION = 0.15\n",
    "CROSSOVER_RATE = 0.75\n",
    "MAX_GENERATIONS = 200\n",
    "TOURNAMENT_SIZE = 7\n",
    "NUM_EPISODES = 2\n",
    "NUM_ELITES = POPULATION_SIZE // 20\n",
    "\n",
    "LOGGING_RESULTS = []\n",
    "LOGGING_CONDITIONS = []\n",
    "LOGGING_ACTIONS = []\n",
    "LOGGING_PERFORMANCE = []\n",
    "\n",
    "USEFUL_RULES = [\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_ON_PLAYER, False), Condition(ConditionType.CAN_MOVE_UP, False)], [OperatorType.AND], ActionType.MOVE_UP), 10),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_ON_PLAYER, False), Condition(ConditionType.CAN_MOVE_DOWN, False)], [OperatorType.AND], ActionType.MOVE_DOWN), 10),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_ON_PLAYER, False), Condition(ConditionType.CAN_MOVE_LEFT, False)], [OperatorType.AND], ActionType.MOVE_LEFT), 10),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_ON_PLAYER, False), Condition(ConditionType.CAN_MOVE_RIGHT, False)], [OperatorType.AND], ActionType.MOVE_RIGHT), 10),\n",
    "    (Rule([Condition(ConditionType.IS_WOOD_IN_RANGE, False), Condition(ConditionType.HAS_BOMB, False)], [OperatorType.AND], ActionType.PLACE_BOMB), 10),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_DOWN, False), Condition(ConditionType.CAN_MOVE_UP, False)], [OperatorType.AND], ActionType.MOVE_UP), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_DOWN, False), Condition(ConditionType.CAN_MOVE_LEFT, False)], [OperatorType.AND], ActionType.MOVE_LEFT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_DOWN, False), Condition(ConditionType.CAN_MOVE_RIGHT, False)], [OperatorType.AND], ActionType.MOVE_RIGHT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_UP, False), Condition(ConditionType.CAN_MOVE_DOWN, False)], [OperatorType.AND], ActionType.MOVE_DOWN), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_UP, False), Condition(ConditionType.CAN_MOVE_LEFT, False)], [OperatorType.AND], ActionType.MOVE_LEFT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_UP, False), Condition(ConditionType.CAN_MOVE_RIGHT, False)], [OperatorType.AND], ActionType.MOVE_RIGHT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_LEFT, False), Condition(ConditionType.CAN_MOVE_DOWN, False)], [OperatorType.AND], ActionType.MOVE_DOWN), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_LEFT, False), Condition(ConditionType.CAN_MOVE_UP, False)], [OperatorType.AND], ActionType.MOVE_UP), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_LEFT, False), Condition(ConditionType.CAN_MOVE_RIGHT, False)], [OperatorType.AND], ActionType.MOVE_RIGHT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_RIGHT, False), Condition(ConditionType.CAN_MOVE_DOWN, False)], [OperatorType.AND], ActionType.MOVE_DOWN), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_RIGHT, False), Condition(ConditionType.CAN_MOVE_UP, False)], [OperatorType.AND], ActionType.MOVE_UP), 1),\n",
    "    (Rule([Condition(ConditionType.IS_BOMB_RIGHT, False), Condition(ConditionType.CAN_MOVE_LEFT, False)], [OperatorType.AND], ActionType.MOVE_LEFT), 1),\n",
    "    (Rule([Condition(ConditionType.IS_ENEMY_IN_RANGE, False), Condition(ConditionType.HAS_BOMB, False)], [OperatorType.AND], ActionType.PLACE_BOMB), 10),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_condition():\n",
    "    condition_type = random.choice(list(ConditionType))\n",
    "    # negation = random.choices([True, False], weights=[0.25, 0.75], k=1)[0]\n",
    "    # negation = random.choices([True, False], weights=[0, 1], k=1)[0]\n",
    "    return Condition(condition_type, False)\n",
    "\n",
    "def random_operator():\n",
    "    return random.choice(list(OperatorType))\n",
    "\n",
    "def random_action():\n",
    "    return random.choice(list(ActionType))\n",
    "\n",
    "def create_random_rule():\n",
    "    num_conditions = random.choices([1, 2, 3], weights=[1, 3, 1], k=1)[0]\n",
    "    conditions = [random_condition() for _ in range(num_conditions)]\n",
    "    \n",
    "    num_operators = num_conditions - 1\n",
    "    operators = [random_operator() for _ in range(num_operators)]\n",
    "    \n",
    "    action = random_action()\n",
    "    \n",
    "    return Rule(conditions, operators, action)\n",
    "\n",
    "def create_individual(num_rules):\n",
    "    num_useful_rules = random.randint(1, 6)\n",
    "    # num_useful_rules = 0\n",
    "    \n",
    "    rules = [rule for rule, _ in USEFUL_RULES]\n",
    "    weights = [weight for _, weight in USEFUL_RULES]\n",
    "    indices = np.random.choice(\n",
    "        len(rules), \n",
    "        size=num_useful_rules,\n",
    "        replace=False,\n",
    "        p=np.array(weights) / sum(weights)\n",
    "    )\n",
    "    useful_sample = [rules[i] for i in indices]\n",
    "\n",
    "    random_rules = [create_random_rule() for _ in range(num_rules - num_useful_rules)]\n",
    "\n",
    "    rules = useful_sample + random_rules\n",
    "    \n",
    "    random.shuffle(rules)\n",
    "\n",
    "    individual = creator.Individual(rules)\n",
    "\n",
    "    return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", create_individual, num_rules=10)\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_rule(rule: Rule):\n",
    "    # 50% chance to add a condition if there are less than 3\n",
    "    if len(rule.conditions) < 3 and random.random() < MUTATION_RATE_ADD_COND:\n",
    "        rule.conditions.append(random_condition())\n",
    "        if len(rule.conditions) > 1:\n",
    "            rule.operators.append(random_operator())\n",
    "\n",
    "    # 50% chance to remove a condition if there are more than 1\n",
    "    if len(rule.conditions) > 1 and random.random() < MUTATION_RATE_REMOVE_COND:\n",
    "        idx = random.randint(0, len(rule.conditions) - 1)\n",
    "        rule.conditions.pop(idx)\n",
    "        if idx < len(rule.operators):\n",
    "            rule.operators.pop(idx)\n",
    "        else:\n",
    "            rule.operators.pop(-1)\n",
    "\n",
    "    if len(rule.conditions) > 0 and random.random() < MUTATION_RATE_REPLACE_COND:\n",
    "        idx = random.randint(0, len(rule.conditions) - 1)\n",
    "        rule.conditions[idx] = random_condition()\n",
    "\n",
    "    # for i in range(len(rule.conditions)):\n",
    "    #     if random.random() < 0.1:\n",
    "    #         rule.conditions[i].negation = not rule.conditions[i].negation\n",
    "\n",
    "    for i in range(len(rule.operators)):\n",
    "        if random.random() < MUTATION_RATE_REPLACE_OPERATOR:\n",
    "            rule.operators[i] = random_operator()\n",
    "            \n",
    "    if random.random() < MUTATION_RATE_REPLACE_ACTION:\n",
    "        rule.action = random_action()\n",
    "        \n",
    "    return rule\n",
    "\n",
    "def mutate_individual(individual):\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < MUTATION_RATE_RULE:\n",
    "            if random.random() < MUTATION_RATE_REPLACE:\n",
    "                individual[i] = create_random_rule()\n",
    "            else:\n",
    "                individual[i] = mutate_rule(individual[i])\n",
    "\n",
    "    if random.random() < MUTATION_RATE_SHUFFLE:\n",
    "        return mutate_shuffle(individual)\n",
    "\n",
    "    return individual,\n",
    "\n",
    "def mutate_shuffle(individual):\n",
    "    if len(individual) < 2:\n",
    "        return individual,\n",
    "    \n",
    "    num_to_shuffle = random.randint(2, len(individual))\n",
    "    indices = random.sample(range(len(individual)), num_to_shuffle)\n",
    "    shuffled_rules = [individual[i] for i in indices]\n",
    "    \n",
    "    random.shuffle(shuffled_rules)\n",
    "    \n",
    "    temp_individual = list(individual)\n",
    "    for i, idx in enumerate(indices):\n",
    "        temp_individual[idx] = shuffled_rules[i]\n",
    "        \n",
    "    return temp_individual,\n",
    "\n",
    "def crossover_individuals(ind1, ind2):\n",
    "    cxpoint1 = random.randint(0, len(ind1) - 1)\n",
    "    cxpoint2 = random.randint(0, len(ind1) - 1)\n",
    "    if cxpoint1 > cxpoint2:\n",
    "        cxpoint1, cxpoint2 = cxpoint2, cxpoint1\n",
    "        \n",
    "    ind1[cxpoint1:cxpoint2], ind2[cxpoint1:cxpoint2] = \\\n",
    "        ind2[cxpoint1:cxpoint2], ind1[cxpoint1:cxpoint2]\n",
    "            \n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tournament(tournament_data):\n",
    "    population, indices = tournament_data\n",
    "    agents = [\n",
    "        GeneticAgent(\n",
    "            rules=population[index], \n",
    "            individual_index=index\n",
    "        ) for index in indices\n",
    "    ]\n",
    "    # agents.append(SimpleAgent())\n",
    "    # agents.append(SimpleAgent())\n",
    "\n",
    "    random.shuffle(agents)\n",
    "\n",
    "    game = Game(agents, max_steps=600)\n",
    "    results = game.play_game(num_episodes=NUM_EPISODES, render_mode=None)\n",
    "    return results\n",
    "\n",
    "def evaluate_population_in_tournament(population, generation, run_id):\n",
    "    fitness_scores = [0] * len(population)\n",
    "\n",
    "    agent_episode_counts = [0] * len(population)\n",
    "    \n",
    "    agents_per_tournament = 4\n",
    "    rounds_per_agent = 5\n",
    "\n",
    "    tournament_data = []\n",
    "    \n",
    "    for _ in range(rounds_per_agent):\n",
    "        shuffled_indices = list(range(len(population)))\n",
    "        random.shuffle(shuffled_indices)\n",
    "        \n",
    "        for i in range(0, len(shuffled_indices), agents_per_tournament):\n",
    "            current_indices = shuffled_indices[i:i + agents_per_tournament]\n",
    "            \n",
    "            if len(current_indices) == agents_per_tournament:\n",
    "                tournament_data.append((population, current_indices))\n",
    "    \n",
    "    processor_count = min(multiprocessing.cpu_count(), len(tournament_data))\n",
    "    with multiprocessing.Pool(processes=processor_count) as pool:\n",
    "        all_results = pool.map(evaluate_tournament, tournament_data)\n",
    "\n",
    "    if generation % 10 == 0:\n",
    "        with open(f'./results/{run_id}/tournament/{generation}.pkl', 'wb') as f:\n",
    "            pickle.dump(all_results, f)\n",
    "\n",
    "    rewards = {\n",
    "        \"TILES\": 15,             # Points per unique tile visited\n",
    "        \"BOMBS\": 75,            # Points per bomb placed\n",
    "        \"WOOD\": 150,             # Points per wood exploded\n",
    "        # \"DISTANCE\": 0.025,          # Points per unit distance from other agents\n",
    "        \"SELF_KILL\": -1000,       # Points for self-kill\n",
    "        \"KILL\": 750,            # Points for killing another agent\n",
    "        \"WIN_WITH_KILLS\": 1000,   # Points for winning with kills\n",
    "        \"WIN_NO_KILLS\": 200,     # Points for winning without kills\n",
    "        \"DIED\": -500,           # Points for dying\n",
    "        \"PASSIVE_TILES\": -50,        # Points for being passive (visited < 10 tiles)\n",
    "        \"PASSIVE_BOMBS\": -100,        # Points for being passive (placed < 4 bombs)\n",
    "        \"TIMEOUT_LOSE\": -150,    # Points for not winning or dying\n",
    "        \"STEP_REWARD\": 0.1, # Points per step taken\n",
    "        \"VISIT_PENALTY\": -5,     # Penalty per excess visit to frequently visited tiles\n",
    "    }\n",
    "\n",
    "    for result in all_results:\n",
    "        for episode_result in result:\n",
    "            agent_results = episode_result.agent_results\n",
    "            for agent_result in agent_results:\n",
    "                agent_episode_counts[agent_result.individual_index] += 1\n",
    "                agent_index = agent_result.individual_index\n",
    "                \n",
    "                visit_penalty = 0\n",
    "                # Calculate visit penalty for frequently visited tiles\n",
    "                for position, visit_count in agent_result.visited_tiles.items():\n",
    "                    if visit_count > 3:  # Penalty threshold\n",
    "                        excess_visits = visit_count - 3\n",
    "                        visit_penalty += excess_visits * rewards[\"VISIT_PENALTY\"]\n",
    "                unique_tiles_visited = len(agent_result.visited_tiles)\n",
    "            \n",
    "                logging_episode_result = {\n",
    "                    'generation': generation,\n",
    "                    'agent_index': agent_index,\n",
    "                    'episode_index': agent_episode_counts[agent_result.individual_index],\n",
    "                    'tiles': unique_tiles_visited * rewards[\"TILES\"],\n",
    "                    'bombs_placed': agent_result.bombs_placed * rewards[\"BOMBS\"],\n",
    "                    'wood_exploded': agent_result.wood_exploded * rewards[\"WOOD\"],\n",
    "                    'distance': 0,\n",
    "                    'self_kill': 0,\n",
    "                    'kills': 0,\n",
    "                    'win': 0,\n",
    "                    'alive': 0,\n",
    "                    'passive_tiles': 0,\n",
    "                    'passive_bombs': 0,\n",
    "                    'visit_penalty': visit_penalty,\n",
    "                    'fitness': 0,\n",
    "                    'step_reward': agent_result.step_count * rewards[\"STEP_REWARD\"],\n",
    "                    'steps': agent_result.step_count,\n",
    "                    'no_satisfied_rules': agent_result.no_satisfied_rules,\n",
    "                }\n",
    "\n",
    "                fitness = 0\n",
    "\n",
    "                fitness += unique_tiles_visited * rewards[\"TILES\"]\n",
    "                fitness += agent_result.bombs_placed * rewards[\"BOMBS\"]\n",
    "                fitness += agent_result.wood_exploded * rewards[\"WOOD\"]\n",
    "                fitness += agent_result.step_count * rewards[\"STEP_REWARD\"]\n",
    "                fitness += visit_penalty  # Add visit penalty to fitness\n",
    "\n",
    "                # In a 11x11 grid, the maximum distance is 20\n",
    "                # normalized_proximity_score = max(0, 20 - agent_result.average_distance)\n",
    "                # proximity_per_step = max(0, 20 - agent_result.average_distance)\n",
    "                # distance_score = proximity_per_step * agent_result.step_count * rewards[\"DISTANCE\"]\n",
    "                # fitness += distance_score\n",
    "                # logging_episode_result['distance'] += round(distance_score, 3)\n",
    "\n",
    "                for kill in agent_result.kills:\n",
    "                    if kill == agent_result.id:\n",
    "                        fitness += rewards[\"SELF_KILL\"]\n",
    "                        logging_episode_result['self_kill'] += rewards[\"SELF_KILL\"]\n",
    "                    else:\n",
    "                        fitness += rewards[\"KILL\"]\n",
    "                        logging_episode_result['kills'] += rewards[\"KILL\"]\n",
    "                        \n",
    "                if agent_result.winner:\n",
    "                    if len(agent_result.kills) > 0:\n",
    "                        fitness += rewards[\"WIN_WITH_KILLS\"]\n",
    "                        logging_episode_result['win'] += rewards[\"WIN_WITH_KILLS\"]\n",
    "                    else:\n",
    "                        fitness += rewards[\"WIN_NO_KILLS\"]\n",
    "                        logging_episode_result['win'] += rewards[\"WIN_NO_KILLS\"]\n",
    "                else:\n",
    "                    if not agent_result.is_alive:\n",
    "                        fitness += rewards[\"DIED\"]\n",
    "                        logging_episode_result['alive'] += rewards[\"DIED\"]\n",
    "                    else:\n",
    "                        fitness += rewards[\"TIMEOUT_LOSE\"]\n",
    "                        logging_episode_result['alive'] += rewards[\"TIMEOUT_LOSE\"]\n",
    "\n",
    "                if unique_tiles_visited < 10:\n",
    "                    tile_penalty = (10 - unique_tiles_visited) * rewards[\"PASSIVE_TILES\"]\n",
    "                    fitness += tile_penalty\n",
    "                    logging_episode_result['passive_tiles'] += tile_penalty\n",
    "                if agent_result.bombs_placed < 4:\n",
    "                    bomb_penalty = (4 - agent_result.bombs_placed) * rewards[\"PASSIVE_BOMBS\"]\n",
    "                    fitness += bomb_penalty\n",
    "                    logging_episode_result['passive_bombs'] += bomb_penalty\n",
    "\n",
    "                logging_episode_result['fitness'] = round(fitness, 3)\n",
    "                LOGGING_RESULTS.append(logging_episode_result)\n",
    "                \n",
    "                fitness_scores[agent_index] += fitness\n",
    "\n",
    "    # Normalize fitness scores\n",
    "    final_fitness_scores = [0.0] * len(fitness_scores)\n",
    "    for i in range(len(fitness_scores)):\n",
    "        if agent_episode_counts[i] > 0:\n",
    "            final_fitness_scores[i] = fitness_scores[i] / agent_episode_counts[i]\n",
    "        \n",
    "    return [(score,) for score in final_fitness_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"mate\", crossover_individuals)\n",
    "toolbox.register(\"mutate\", mutate_individual)\n",
    "toolbox.register(\"mutate_shuffle\", mutate_shuffle)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_structure(run_id):\n",
    "    if not os.path.exists('./results'):\n",
    "        os.makedirs('./results')\n",
    "    if not os.path.exists(f'./results/{run_id}'):\n",
    "        os.makedirs(f'./results/{run_id}')\n",
    "    if not os.path.exists(f'./results/{run_id}/tournament'):\n",
    "        os.makedirs(f'./results/{run_id}/tournament')\n",
    "        \n",
    "    LOGGING_RESULTS.clear()\n",
    "    LOGGING_CONDITIONS.clear()\n",
    "    LOGGING_ACTIONS.clear()\n",
    "    LOGGING_PERFORMANCE.clear()\n",
    "\n",
    "def get_performance_data(gen, pop, hof):\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    min = np.min(fits)\n",
    "    max = np.max(fits)\n",
    "    std = np.std(fits)\n",
    "    best_fitness = hof[0].fitness.values[0]\n",
    "\n",
    "    LOGGING_PERFORMANCE.append({\n",
    "        'generation': gen,\n",
    "        'mean': round(mean, 3),\n",
    "        'min': round(min, 3),\n",
    "        'max': round(max, 3),\n",
    "        'std': round(std, 3),\n",
    "        'best_fitness': round(best_fitness, 3),\n",
    "    })\n",
    "\n",
    "    return mean, min, max, std, best_fitness\n",
    "\n",
    "def get_conditions_actions_data(gen, pop: List[List[Rule]]):\n",
    "    pop_conditions = {\n",
    "        \"generation\": gen,\n",
    "    }\n",
    "    for condition in ConditionType:\n",
    "        for negation in [True, False]:\n",
    "            pop_conditions[(condition.name, negation)] = 0\n",
    "    pop_actions = {\n",
    "        \"generation\": gen,\n",
    "    }\n",
    "    for action in ActionType:\n",
    "        pop_actions[action] = 0\n",
    "\n",
    "    for individual in pop:\n",
    "        for rule in individual:\n",
    "            for condition in rule.conditions:\n",
    "                condition_key = (condition.condition_type.name, condition.negation)\n",
    "                pop_conditions[condition_key] += 1\n",
    "            pop_actions[rule.action] += 1\n",
    "            \n",
    "    LOGGING_CONDITIONS.append(pop_conditions)\n",
    "    LOGGING_ACTIONS.append(pop_actions)\n",
    "\n",
    "    return pop_conditions, pop_actions\n",
    "        \n",
    "def save_results(run_id, gen):\n",
    "    with open(f'./results/{run_id}/conditions.csv', 'a') as f:\n",
    "        fieldnames = LOGGING_CONDITIONS[0].keys()\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if gen == 0:\n",
    "            writer.writeheader()\n",
    "        for result in LOGGING_CONDITIONS:\n",
    "            writer.writerow(result)\n",
    "        \n",
    "    with open(f'./results/{run_id}/actions.csv', 'a') as f:\n",
    "        fieldnames = LOGGING_ACTIONS[0].keys()\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if gen == 0:\n",
    "            writer.writeheader()\n",
    "        for result in LOGGING_ACTIONS:\n",
    "            writer.writerow(result)\n",
    "\n",
    "    with open(f\"./results/{run_id}/agent_episodes.csv\", \"a\", newline='') as csvfile:\n",
    "        fieldnames = LOGGING_RESULTS[0].keys()\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if gen == 0:\n",
    "            writer.writeheader()\n",
    "        for result in LOGGING_RESULTS:\n",
    "            writer.writerow(result)\n",
    "\n",
    "    with open(f\"./results/{run_id}/performance.csv\", \"a\", newline='') as csvfile:\n",
    "        fieldnames = LOGGING_PERFORMANCE[0].keys()\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if gen == 0:\n",
    "            writer.writeheader()\n",
    "        for result in LOGGING_PERFORMANCE:\n",
    "            writer.writerow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution(n_gen=MAX_GENERATIONS, pop_size=POPULATION_SIZE, run_id=None):\n",
    "    create_folder_structure(run_id)\n",
    "\n",
    "    pop_size = (pop_size // 4) * 4\n",
    "    if pop_size < 4:\n",
    "        pop_size = 4\n",
    "    \n",
    "    print(f\"Starting evolution with population size: {pop_size}\")\n",
    "    \n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    \n",
    "    fitnesses = evaluate_population_in_tournament(pop, 0, run_id)\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    hof = tools.HallOfFame(2)\n",
    "    hof.update(pop)\n",
    "\n",
    "    get_performance_data(0, pop, hof)\n",
    "    get_conditions_actions_data(0, pop)\n",
    "\n",
    "    save_results(run_id, 0)\n",
    "    \n",
    "    for gen in range(1, n_gen + 1):\n",
    "        print(f\"Generation {gen}/{n_gen}\")\n",
    "        LOGGING_CONDITIONS.clear()\n",
    "        LOGGING_ACTIONS.clear()\n",
    "        LOGGING_PERFORMANCE.clear()\n",
    "        LOGGING_RESULTS.clear()\n",
    "\n",
    "        elites = tools.selBest(pop, NUM_ELITES)\n",
    "        elites = [toolbox.clone(ind) for ind in elites]\n",
    "        \n",
    "        offspring = toolbox.select(pop, len(pop) - NUM_ELITES)\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        \n",
    "        for i in range(0, len(offspring), 2):\n",
    "            if i + 1 < len(offspring):\n",
    "                if random.random() < CROSSOVER_RATE:\n",
    "                    toolbox.mate(offspring[i], offspring[i + 1])\n",
    "                    del offspring[i].fitness.values\n",
    "                    del offspring[i + 1].fitness.values\n",
    "\n",
    "        for i in range(len(offspring)):\n",
    "            if random.random() < MUTATION_RATE:\n",
    "                toolbox.mutate(offspring[i])\n",
    "                del offspring[i].fitness.values\n",
    "\n",
    "        pop[:] = offspring + elites\n",
    "\n",
    "        fitnesses = evaluate_population_in_tournament(pop, gen, run_id)\n",
    "        for ind, fit in zip(pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            \n",
    "        hof.update(pop)\n",
    "        \n",
    "        mean, min, max, std, best_fitness = get_performance_data(gen, pop, hof)\n",
    "        \n",
    "        print(f\"  Avg: {round(mean, 3)}\")\n",
    "        print(f\"  Min: {round(min, 3)}\")\n",
    "        print(f\"  Max: {round(max, 3)}\")\n",
    "        print(f\"  Std: {round(std, 3)}\")\n",
    "        print(f\"  Best individual fitness: {round(best_fitness, 3)}\")\n",
    "\n",
    "        get_conditions_actions_data(gen, pop)\n",
    "\n",
    "        with open(f'./results/{run_id}/best_individual.pkl', 'wb') as f:\n",
    "            pickle.dump(hof[0], f)\n",
    "\n",
    "        save_results(run_id, gen)\n",
    "\n",
    "    return pop, stats, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 86541\n",
      "Starting evolution with population size: 200\n",
      "Generation 1/200\n",
      "  Avg: -2117.057\n",
      "  Min: -3585.9\n",
      "  Max: -1053.86\n",
      "  Std: 443.532\n",
      "  Best individual fitness: -1053.86\n",
      "Generation 2/200\n",
      "  Avg: -1936.858\n",
      "  Min: -3819.0\n",
      "  Max: -1108.94\n",
      "  Std: 366.525\n",
      "  Best individual fitness: -1053.86\n",
      "Generation 3/200\n",
      "  Avg: -1848.009\n",
      "  Min: -3244.09\n",
      "  Max: -806.51\n",
      "  Std: 381.421\n",
      "  Best individual fitness: -806.51\n",
      "Generation 4/200\n",
      "  Avg: -2010.324\n",
      "  Min: -3548.8\n",
      "  Max: -1100.78\n",
      "  Std: 415.496\n",
      "  Best individual fitness: -806.51\n",
      "Generation 5/200\n",
      "  Avg: -2015.607\n",
      "  Min: -3798.0\n",
      "  Max: -1158.1\n",
      "  Std: 429.569\n",
      "  Best individual fitness: -806.51\n",
      "Generation 6/200\n",
      "  Avg: -1841.868\n",
      "  Min: -3506.8\n",
      "  Max: -1064.63\n",
      "  Std: 355.339\n",
      "  Best individual fitness: -806.51\n",
      "Generation 7/200\n",
      "  Avg: -1894.293\n",
      "  Min: -3514.8\n",
      "  Max: -817.54\n",
      "  Std: 410.13\n",
      "  Best individual fitness: -806.51\n",
      "Generation 8/200\n",
      "  Avg: -1815.673\n",
      "  Min: -3145.68\n",
      "  Max: -904.13\n",
      "  Std: 347.624\n",
      "  Best individual fitness: -806.51\n",
      "Generation 9/200\n",
      "  Avg: -2057.091\n",
      "  Min: -3784.0\n",
      "  Max: -1110.04\n",
      "  Std: 509.938\n",
      "  Best individual fitness: -806.51\n",
      "Generation 10/200\n",
      "  Avg: -1844.441\n",
      "  Min: -3707.0\n",
      "  Max: -656.94\n",
      "  Std: 441.942\n",
      "  Best individual fitness: -656.94\n",
      "Generation 11/200\n",
      "  Avg: -1912.813\n",
      "  Min: -3802.0\n",
      "  Max: -965.46\n",
      "  Std: 487.763\n",
      "  Best individual fitness: -656.94\n",
      "Generation 12/200\n",
      "  Avg: -1713.507\n",
      "  Min: -2949.81\n",
      "  Max: -781.18\n",
      "  Std: 383.938\n",
      "  Best individual fitness: -656.94\n",
      "Generation 13/200\n",
      "  Avg: -1570.469\n",
      "  Min: -3146.58\n",
      "  Max: -152.32\n",
      "  Std: 417.183\n",
      "  Best individual fitness: -152.32\n",
      "Generation 14/200\n",
      "  Avg: -1506.036\n",
      "  Min: -2958.7\n",
      "  Max: -351.49\n",
      "  Std: 463.365\n",
      "  Best individual fitness: -152.32\n",
      "Generation 15/200\n",
      "  Avg: -1469.277\n",
      "  Min: -3403.6\n",
      "  Max: -427.38\n",
      "  Std: 498.043\n",
      "  Best individual fitness: -152.32\n",
      "Generation 16/200\n",
      "  Avg: -1257.12\n",
      "  Min: -3254.8\n",
      "  Max: 254.84\n",
      "  Std: 486.536\n",
      "  Best individual fitness: 254.84\n",
      "Generation 17/200\n",
      "  Avg: -1311.495\n",
      "  Min: -3024.99\n",
      "  Max: 599.1\n",
      "  Std: 551.57\n",
      "  Best individual fitness: 599.1\n",
      "Generation 18/200\n",
      "  Avg: -1010.649\n",
      "  Min: -2049.8\n",
      "  Max: 424.3\n",
      "  Std: 497.287\n",
      "  Best individual fitness: 599.1\n",
      "Generation 19/200\n",
      "  Avg: -912.88\n",
      "  Min: -2109.8\n",
      "  Max: -7.1\n",
      "  Std: 471.039\n",
      "  Best individual fitness: 599.1\n",
      "Generation 20/200\n",
      "  Avg: -855.21\n",
      "  Min: -2104.0\n",
      "  Max: 147.7\n",
      "  Std: 468.323\n",
      "  Best individual fitness: 599.1\n",
      "Generation 21/200\n",
      "  Avg: -886.03\n",
      "  Min: -2414.8\n",
      "  Max: 107.0\n",
      "  Std: 443.886\n",
      "  Best individual fitness: 599.1\n",
      "Generation 22/200\n",
      "  Avg: -868.195\n",
      "  Min: -2622.7\n",
      "  Max: 5.9\n",
      "  Std: 430.938\n",
      "  Best individual fitness: 599.1\n",
      "Generation 23/200\n",
      "  Avg: -878.591\n",
      "  Min: -2193.08\n",
      "  Max: 312.2\n",
      "  Std: 467.702\n",
      "  Best individual fitness: 599.1\n",
      "Generation 24/200\n",
      "  Avg: -843.952\n",
      "  Min: -2058.56\n",
      "  Max: 114.6\n",
      "  Std: 425.904\n",
      "  Best individual fitness: 599.1\n",
      "Generation 25/200\n",
      "  Avg: -888.664\n",
      "  Min: -3000.7\n",
      "  Max: 1005.55\n",
      "  Std: 480.0\n",
      "  Best individual fitness: 1005.55\n",
      "Generation 26/200\n",
      "  Avg: -789.812\n",
      "  Min: -2338.5\n",
      "  Max: 386.64\n",
      "  Std: 586.176\n",
      "  Best individual fitness: 1005.55\n",
      "Generation 27/200\n",
      "  Avg: -627.42\n",
      "  Min: -2114.47\n",
      "  Max: 764.01\n",
      "  Std: 640.064\n",
      "  Best individual fitness: 1005.55\n",
      "Generation 28/200\n",
      "  Avg: -403.574\n",
      "  Min: -2949.44\n",
      "  Max: 1179.53\n",
      "  Std: 609.79\n",
      "  Best individual fitness: 1179.53\n",
      "Generation 29/200\n",
      "  Avg: -426.815\n",
      "  Min: -2905.15\n",
      "  Max: 1290.35\n",
      "  Std: 664.775\n",
      "  Best individual fitness: 1290.35\n",
      "Generation 30/200\n",
      "  Avg: -340.311\n",
      "  Min: -2125.84\n",
      "  Max: 1642.53\n",
      "  Std: 620.869\n",
      "  Best individual fitness: 1642.53\n",
      "Generation 31/200\n",
      "  Avg: -384.004\n",
      "  Min: -2349.35\n",
      "  Max: 1027.44\n",
      "  Std: 656.172\n",
      "  Best individual fitness: 1642.53\n",
      "Generation 32/200\n",
      "  Avg: -434.186\n",
      "  Min: -2992.37\n",
      "  Max: 811.1\n",
      "  Std: 683.77\n",
      "  Best individual fitness: 1642.53\n",
      "Generation 33/200\n",
      "  Avg: -483.763\n",
      "  Min: -3531.79\n",
      "  Max: 1205.44\n",
      "  Std: 768.631\n",
      "  Best individual fitness: 1642.53\n",
      "Generation 34/200\n",
      "  Avg: -408.212\n",
      "  Min: -2870.08\n",
      "  Max: 703.73\n",
      "  Std: 613.946\n",
      "  Best individual fitness: 1642.53\n",
      "Generation 35/200\n",
      "  Avg: -397.327\n",
      "  Min: -2645.66\n",
      "  Max: 1022.57\n",
      "  Std: 680.219\n",
      "  Best individual fitness: 1642.53\n",
      "Generation 36/200\n"
     ]
    }
   ],
   "source": [
    "# import pstats\n",
    "# import io\n",
    "\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    "\n",
    "RUN_ID = np.random.randint(0, 100000)\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "final_pop, stats, hof = run_evolution(n_gen=MAX_GENERATIONS, pop_size=POPULATION_SIZE, run_id=RUN_ID)\n",
    "\n",
    "print(\"Best agent in final population:\")\n",
    "# sort final population by fitness\n",
    "final_pop.sort(key=lambda ind: ind.fitness.values[0], reverse=True)\n",
    "print(f\"Best individual fitness: {final_pop[0].fitness.values[0]}\")\n",
    "print(f\"Best individual has {len(final_pop[0])} rules:\")\n",
    "for rule in final_pop[0]:\n",
    "    print(rule)\n",
    "\n",
    "print(\"\\nEvolution finished.\")\n",
    "print(f\"Stored best individual in ./results/{RUN_ID}/best_individual.pkl\")\n",
    "print(f\"Best individual has {len(hof[0])} rules with fitness: {hof[0].fitness.values[0]}\")\n",
    "print(\"Best individual rules:\")\n",
    "for rule in hof[0]:\n",
    "    print(rule)\n",
    "\n",
    "# pr.disable()\n",
    "# s = io.StringIO()\n",
    "# ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')\n",
    "# ps.print_stats(15)\n",
    "# print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f GeneticAgent.act run_evolution(n_gen=1, pop_size=20, run_id=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
