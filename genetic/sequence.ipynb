{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "from genetic.common_types import Rule, ConditionType, OperatorType, ActionType\n",
    "from genetic.test_agent import GeneticAgent\n",
    "from genetic.game import Game\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pommerman.agents import PlayerAgent\n",
    "\n",
    "if \"FitnessMax\" in creator.__dict__:\n",
    "    del creator.FitnessMax\n",
    "if \"Individual\" in creator.__dict__:\n",
    "    del creator.Individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 100\n",
    "\n",
    "\n",
    "custom_map = [\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],  # Border walls\n",
    "    [1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1],  # Player 0 starting area\n",
    "    [1, 0, 1, 2, 1, 2, 1, 2, 1, 0, 1],\n",
    "    [1, 0, 2, 0, 2, 0, 2, 0, 2, 0, 1],\n",
    "    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    [1, 0, 2, 0, 2, 0, 2, 0, 2, 0, 1],  # Middle row\n",
    "    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    [1, 0, 2, 0, 2, 0, 2, 0, 2, 0, 1],\n",
    "    [1, 0, 1, 2, 1, 2, 1, 2, 1, 0, 1],\n",
    "    [1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 1],  # Player 3 starting area\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],  # Border walls\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_condition():\n",
    "    return random.choice(list(ConditionType))\n",
    "\n",
    "def random_operator():\n",
    "    return random.choice(list(OperatorType))\n",
    "\n",
    "def random_action():\n",
    "    return random.choice(list(ActionType))\n",
    "\n",
    "def create_random_rule():\n",
    "    num_conditions = random.randint(1, 3)\n",
    "    conditions = [random_condition() for _ in range(num_conditions)]\n",
    "    \n",
    "    num_operators = num_conditions - 1\n",
    "    operators = [random_operator() for _ in range(num_operators)]\n",
    "    \n",
    "    action = random_action()\n",
    "    \n",
    "    return Rule(conditions, operators, action)\n",
    "\n",
    "def create_individual(num_rules):\n",
    "    return [create_random_rule() for _ in range(num_rules)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"rule\", create_random_rule)\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "                toolbox.rule, n=10)\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_rule(rule, indpb=0.1):\n",
    "    if random.random() < indpb:\n",
    "        if len(rule.conditions) < 3 and random.random() < 0.5:\n",
    "            rule.conditions.append(random_condition())\n",
    "            if len(rule.conditions) > 1:\n",
    "                rule.operators.append(random_operator())\n",
    "        elif len(rule.conditions) > 1 and random.random() < 0.5:\n",
    "            idx = random.randint(0, len(rule.conditions) - 1)\n",
    "            rule.conditions.pop(idx)\n",
    "            if idx < len(rule.operators):\n",
    "                rule.operators.pop(idx)\n",
    "            else:\n",
    "                rule.operators.pop(-1)\n",
    "        else:\n",
    "            idx = random.randint(0, len(rule.conditions) - 1)\n",
    "            rule.conditions[idx] = random_condition()\n",
    "\n",
    "    for i in range(len(rule.operators)):\n",
    "        if random.random() < indpb:\n",
    "            rule.operators[i] = random_operator()\n",
    "            \n",
    "    if random.random() < indpb:\n",
    "        rule.action = random_action()\n",
    "        \n",
    "    return rule\n",
    "\n",
    "\n",
    "def mutate_individual(individual, indpb=0.1):\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < indpb:\n",
    "            individual[i] = mutate_rule(individual[i], indpb)\n",
    "\n",
    "    return individual,\n",
    "\n",
    "def crossover_individuals(ind1, ind2):\n",
    "    if len(ind1) != len(ind2):\n",
    "        raise ValueError(\"Individuals must have the same number of rules for crossover.\")\n",
    "    \n",
    "    cxpoint1 = random.randint(0, len(ind1))\n",
    "    cxpoint2 = random.randint(0, len(ind1))\n",
    "    if cxpoint1 > cxpoint2:\n",
    "        cxpoint1, cxpoint2 = cxpoint2, cxpoint1\n",
    "        \n",
    "    ind1[cxpoint1:cxpoint2], ind2[cxpoint1:cxpoint2] = \\\n",
    "        ind2[cxpoint1:cxpoint2], ind1[cxpoint1:cxpoint2]\n",
    "        \n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population_in_tournament(population):\n",
    "    fitness_scores = [0] * len(population)\n",
    "    num_tournaments = len(population) // 4\n",
    "        \n",
    "    for tournament in range(num_tournaments):\n",
    "        competitors_indices = np.random.choice(len(population), 4, replace=False)\n",
    "\n",
    "        competitors = [population[i] for i in competitors_indices]\n",
    "        agents = [GeneticAgent(rules=competitor) for competitor in competitors]\n",
    "\n",
    "        game = Game(agents, custom_map=custom_map)\n",
    "        \n",
    "        results = game.play_game(num_episodes=3, render_mode=None)\n",
    "        \n",
    "        for episode_result in results:\n",
    "            winners = episode_result['winners'] or []\n",
    "            for winner in winners:\n",
    "                pop_idx = competitors_indices[winner]\n",
    "                fitness_scores[pop_idx] += 10\n",
    "                \n",
    "            survival_steps = episode_result['survival_steps']\n",
    "            for agent_idx, steps in enumerate(survival_steps):\n",
    "                pop_idx = competitors_indices[agent_idx]\n",
    "                fitness_scores[pop_idx] += steps / 50\n",
    "                \n",
    "    return [(score,) for score in fitness_scores]\n",
    "        \n",
    "        \n",
    "def evaluate_individual(individual):\n",
    "    return (0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"mate\", crossover_individuals)\n",
    "toolbox.register(\"mutate\", mutate_individual, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evaluate_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution(n_gen=10, pop_size=40):\n",
    "    pop_size = (pop_size // 4) * 4\n",
    "    if pop_size < 4:\n",
    "        pop_size = 4\n",
    "        \n",
    "    print(f\"Starting evolution with population size: {pop_size}\")\n",
    "    \n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    \n",
    "    fitnesses = evaluate_population_in_tournament(pop)\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    hof = tools.HallOfFame(5)\n",
    "    \n",
    "    for gen in range(n_gen):\n",
    "        print(f\"Generation {gen + 1}/{n_gen}\")\n",
    "        \n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "        \n",
    "        for i in range(0, len(offspring), 2):\n",
    "            if i + 1 < len(offspring):\n",
    "                if random.random() < 0.7:\n",
    "                    toolbox.mate(offspring[i], offspring[i + 1])\n",
    "                    del offspring[i].fitness.values\n",
    "                    del offspring[i + 1].fitness.values\n",
    "\n",
    "        for i in range(len(offspring)):\n",
    "            if random.random() < 0.2:\n",
    "                toolbox.mutate(offspring[i])\n",
    "                del offspring[i].fitness.values\n",
    "                \n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = evaluate_population_in_tournament(invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            \n",
    "        pop[:] = offspring\n",
    "        \n",
    "        hof.update(pop)\n",
    "        \n",
    "        fits = [ind.fitness.values[0] for ind in pop]\n",
    "        length = len(pop)\n",
    "        mean = sum(fits) / length\n",
    "        sum2 = sum(x*x for x in fits)\n",
    "        std = abs(sum2 / length - mean**2)**0.5\n",
    "        \n",
    "        print(f\"  Min: {np.min(fits)}\")\n",
    "        print(f\"  Max: {np.max(fits)}\")\n",
    "        print(f\"  Avg: {mean}\")\n",
    "        print(f\"  Best individual fitness: {hof[0].fitness.values[0]:.2f}\")\n",
    "\n",
    "    return pop, stats, hof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pop, stats, hof = run_evolution(n_gen=10, pop_size=POPULATION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evolution with population size: 100\n",
      "Generation 1/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 13.957800000000002\n",
      "  Best individual fitness: 60.00\n",
      "Generation 2/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 14.349200000000002\n",
      "  Best individual fitness: 60.00\n",
      "Generation 3/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 16.279600000000002\n",
      "  Best individual fitness: 60.00\n",
      "Generation 4/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 13.9672\n",
      "  Best individual fitness: 60.00\n",
      "Generation 5/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 12.612400000000001\n",
      "  Best individual fitness: 60.00\n",
      "Generation 6/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 13.532800000000002\n",
      "  Best individual fitness: 60.00\n",
      "Generation 7/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.28\n",
      "  Best individual fitness: 60.00\n",
      "Generation 8/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 15.36\n",
      "  Best individual fitness: 60.00\n",
      "Generation 9/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 15.0\n",
      "  Best individual fitness: 60.00\n",
      "Generation 10/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 16.56\n",
      "  Best individual fitness: 60.00\n",
      "Generation 11/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 15.12\n",
      "  Best individual fitness: 60.00\n",
      "Generation 12/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 15.6\n",
      "  Best individual fitness: 60.00\n",
      "Generation 13/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 18.48\n",
      "  Best individual fitness: 60.00\n",
      "Generation 14/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 14.88\n",
      "  Best individual fitness: 60.00\n",
      "Generation 15/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 13.68\n",
      "  Best individual fitness: 60.00\n",
      "Generation 16/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 14.52\n",
      "  Best individual fitness: 60.00\n",
      "Generation 17/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.28\n",
      "  Best individual fitness: 60.00\n",
      "Generation 18/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.76\n",
      "  Best individual fitness: 60.00\n",
      "Generation 19/50\n",
      "  Min: 0.0\n",
      "  Max: 72.0\n",
      "  Avg: 14.88\n",
      "  Best individual fitness: 72.00\n",
      "Generation 20/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 15.36\n",
      "  Best individual fitness: 72.00\n",
      "Generation 21/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.76\n",
      "  Best individual fitness: 72.00\n",
      "Generation 22/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 15.84\n",
      "  Best individual fitness: 72.00\n",
      "Generation 23/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.4066\n",
      "  Best individual fitness: 72.00\n",
      "Generation 24/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 16.8\n",
      "  Best individual fitness: 72.00\n",
      "Generation 25/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 15.24\n",
      "  Best individual fitness: 72.00\n",
      "Generation 26/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 14.4\n",
      "  Best individual fitness: 72.00\n",
      "Generation 27/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 17.287\n",
      "  Best individual fitness: 72.00\n",
      "Generation 28/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.64\n",
      "  Best individual fitness: 72.00\n",
      "Generation 29/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 13.603800000000001\n",
      "  Best individual fitness: 72.00\n",
      "Generation 30/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.16\n",
      "  Best individual fitness: 72.00\n",
      "Generation 31/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 14.28\n",
      "  Best individual fitness: 72.00\n",
      "Generation 32/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 14.76\n",
      "  Best individual fitness: 72.00\n",
      "Generation 33/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 15.48\n",
      "  Best individual fitness: 72.00\n",
      "Generation 34/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.52\n",
      "  Best individual fitness: 72.00\n",
      "Generation 35/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 16.2\n",
      "  Best individual fitness: 72.00\n",
      "Generation 36/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 16.8\n",
      "  Best individual fitness: 72.00\n",
      "Generation 37/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 14.28\n",
      "  Best individual fitness: 72.00\n",
      "Generation 38/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 13.8\n",
      "  Best individual fitness: 72.00\n",
      "Generation 39/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.4\n",
      "  Best individual fitness: 72.00\n",
      "Generation 40/50\n",
      "  Min: 0.0\n",
      "  Max: 48.0\n",
      "  Avg: 14.28\n",
      "  Best individual fitness: 72.00\n",
      "Generation 41/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 15.24\n",
      "  Best individual fitness: 72.00\n",
      "Generation 42/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 17.76\n",
      "  Best individual fitness: 72.00\n",
      "Generation 43/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 18.0\n",
      "  Best individual fitness: 72.00\n",
      "Generation 44/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 16.44\n",
      "  Best individual fitness: 72.00\n",
      "Generation 45/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 16.56\n",
      "  Best individual fitness: 72.00\n",
      "Generation 46/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 16.56\n",
      "  Best individual fitness: 72.00\n",
      "Generation 47/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 15.6\n",
      "  Best individual fitness: 72.00\n",
      "Generation 48/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 16.44\n",
      "  Best individual fitness: 72.00\n",
      "Generation 49/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 15.96\n",
      "  Best individual fitness: 72.00\n",
      "Generation 50/50\n",
      "  Min: 0.0\n",
      "  Max: 60.0\n",
      "  Avg: 18.48\n",
      "  Best individual fitness: 72.00\n",
      "\n",
      "Evolution finished.\n",
      "Best individual has 10 rules with fitness: 72.0\n",
      "Best individual rules:\n",
      "IF IS_BOMB_UP AND IS_BOMB_RIGHT THEN MOVE_DOWN\n",
      "IF CAN_MOVE_UP THEN MOVE_LEFT\n",
      "IF CAN_MOVE_UP OR CAN_MOVE_RIGHT THEN MOVE_RIGHT\n",
      "IF CAN_MOVE_UP THEN MOVE_DOWN\n",
      "IF IS_BOMB_IN_RANGE OR IS_BOMB_DOWN THEN MOVE_RIGHT\n",
      "IF IS_BOMB_DOWN THEN MOVE_UP\n",
      "IF IS_BOMB_DOWN OR IS_BOMB_DOWN THEN MOVE_DOWN\n",
      "IF IS_BOMB_IN_RANGE THEN MOVE_LEFT\n",
      "IF IS_BOMB_RIGHT AND CAN_MOVE_UP AND CAN_MOVE_LEFT THEN MOVE_LEFT\n",
      "IF IS_BOMB_IN_RANGE OR IS_BOMB_RIGHT THEN DO_NOTHING\n",
      "\n",
      "Best individual saved to best_individual.pkl.\n"
     ]
    }
   ],
   "source": [
    "final_pop, stats, hof = run_evolution(n_gen=50, pop_size=POPULATION_SIZE)\n",
    "\n",
    "print(\"\\nEvolution finished.\")\n",
    "print(f\"Best individual has {len(hof[0])} rules with fitness: {hof[0].fitness.values[0]}\")\n",
    "print(\"Best individual rules:\")\n",
    "for rule in hof[0]:\n",
    "    print(rule)\n",
    "    \n",
    "with open(\"best_individual.pkl\", \"wb\") as f:\n",
    "    pickle.dump(hof[0], f)\n",
    "    \n",
    "print(\"\\nBest individual saved to best_individual.pkl.\")\n",
    "\n",
    "best_agent = GeneticAgent(rules=hof[0])\n",
    "game = Game([best_agent, PlayerAgent()], custom_map=custom_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
