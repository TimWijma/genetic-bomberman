{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef925d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed485cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_data(run_id):\n",
    "    df_conditions = pd.read_csv(f'./results/{run_id}/conditions.csv')\n",
    "    df_conditions['run_id'] = run_id\n",
    "    df_conditions_melted = df_conditions.melt(id_vars=['generation', 'run_id'], var_name='condition', value_name='value')\n",
    "\n",
    "    df_actions = pd.read_csv(f'./results/{run_id}/actions.csv')\n",
    "    df_actions['run_id'] = run_id\n",
    "    df_actions_melted = df_actions.melt(id_vars=['generation', 'run_id'], var_name='action', value_name='value')\n",
    "\n",
    "    df_performance = pd.read_csv(f'./results/{run_id}/performance.csv')\n",
    "    df_performance = df_performance.drop(columns=['best_fitness', 'std'])\n",
    "\n",
    "    df_performance['run_id'] = run_id\n",
    "    df_performance_melted = df_performance.melt(id_vars=['generation', 'run_id'], var_name='metric', value_name='value')\n",
    "\n",
    "    return df_conditions_melted, df_actions_melted, df_performance_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93104522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN_ID = 6128\n",
    "RUN_IDS = [6128, 1, 2]\n",
    "\n",
    "all_conditions = []\n",
    "all_actions = []\n",
    "all_performance = []\n",
    "\n",
    "for RUN_ID in RUN_IDS:\n",
    "    df_conditions, df_actions, df_performance = get_run_data(RUN_ID)\n",
    "    all_conditions.append(df_conditions)\n",
    "    all_actions.append(df_actions)\n",
    "    all_performance.append(df_performance)\n",
    "\n",
    "combined_conditions = pd.concat(all_conditions)\n",
    "combined_actions = pd.concat(all_actions)\n",
    "combined_performance = pd.concat(all_performance)\n",
    "\n",
    "final_generation_df = combined_conditions['generation'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa150d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_generation_conditions_mean_values = combined_conditions[\n",
    "    combined_conditions['generation'] == final_generation_df\n",
    "].groupby('condition')['value'].mean()\n",
    "\n",
    "ordered_conditions = final_generation_conditions_mean_values.sort_values(ascending=False).index.tolist()\n",
    "\n",
    "combined_conditions['condition'] = pd.Categorical(\n",
    "    combined_conditions['condition'], categories=ordered_conditions, ordered=True\n",
    ")\n",
    "\n",
    "combined_df_conditions_melted_sorted = combined_conditions.sort_values(by='condition')\n",
    "\n",
    "fig_conditions, ax_conditions = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=combined_df_conditions_melted_sorted,\n",
    "    x='generation',\n",
    "    y='value',\n",
    "    hue='condition',\n",
    "    ax=ax_conditions,\n",
    "    estimator='mean',  # Plot the mean value for each condition per generation\n",
    "    errorbar='sd',     # Show the standard deviation as a shaded area\n",
    "    # You can also use errorbar=('ci', 95) for 95% confidence interval\n",
    ")\n",
    "\n",
    "ax_conditions.set_title(\"Mean Condition Frequencies Over Generations (Aggregated Across Runs)\")\n",
    "ax_conditions.set_xlabel(\"Generation\")\n",
    "ax_conditions.set_ylabel(\"Mean Frequency\")\n",
    "\n",
    "handles_act, labels_act = ax_conditions.get_legend_handles_labels()\n",
    "\n",
    "new_labels_act = []\n",
    "for label in labels_act:\n",
    "    # Get the average value at the final generation for this specific condition\n",
    "    mean_value_at_final = final_generation_conditions_mean_values.get(label, 'N/A')\n",
    "\n",
    "    if mean_value_at_final == 'N/A':\n",
    "        new_labels_act.append(f\"{label} (N/A)\") # Handle cases where condition might not be in final_generation_conditions_mean_values\n",
    "    else:\n",
    "        new_labels_act.append(f\"{label} ({mean_value_at_final:.0f})\")\n",
    "\n",
    "# Update the legend with new labels and correct position\n",
    "ax_conditions.legend(handles=handles_act, labels=new_labels_act, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "fig_conditions.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Final Generation conditions (mean across runs):\")\n",
    "print(final_generation_conditions_mean_values.sort_values(ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_generation_actions_mean_values = combined_actions[\n",
    "    combined_actions['generation'] == final_generation_df\n",
    "].groupby('action')['value'].mean()\n",
    "\n",
    "ordered_actions = final_generation_actions_mean_values.sort_values(ascending=False).index.tolist()\n",
    "\n",
    "combined_actions['action'] = pd.Categorical(\n",
    "    combined_actions['action'], categories=ordered_actions, ordered=True\n",
    ")\n",
    "\n",
    "combined_df_actions_melted_sorted = combined_actions.sort_values(by='action')\n",
    "\n",
    "fig_actions, ax_actions = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=combined_df_actions_melted_sorted,\n",
    "    x='generation',\n",
    "    y='value',\n",
    "    hue='action',\n",
    "    ax=ax_actions,\n",
    "    estimator='mean',  # Plot the mean value for each action per generation\n",
    "    errorbar='sd',     # Show the standard deviation as a shaded area\n",
    ")\n",
    "\n",
    "ax_actions.set_title(\"Mean Action Frequencies Over Generations (Aggregated Across Runs)\")\n",
    "ax_actions.set_xlabel(\"Generation\")\n",
    "ax_actions.set_ylabel(\"Mean Frequency\")\n",
    "\n",
    "handles_act, labels_act = ax_actions.get_legend_handles_labels()\n",
    "\n",
    "new_labels_act = []\n",
    "for label in labels_act:\n",
    "    # Get the average value at the final generation for this specific action\n",
    "    mean_value_at_final = final_generation_actions_mean_values.get(label, 'N/A')\n",
    "\n",
    "    if mean_value_at_final == 'N/A':\n",
    "        new_labels_act.append(f\"{label} (N/A)\") # Handle cases where action might not be in final_generation_actions_mean_values\n",
    "    else:\n",
    "        new_labels_act.append(f\"{label} ({mean_value_at_final:.0f})\")\n",
    "# Update the legend with new labels and correct position\n",
    "ax_actions.legend(handles=handles_act, labels=new_labels_act, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "fig_actions.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Final Generation actions (mean across runs):\")\n",
    "print(final_generation_actions_mean_values.sort_values(ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717944a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_generation_performance_mean_values = combined_performance[\n",
    "    combined_performance['generation'] == final_generation_df\n",
    "].groupby('metric')['value'].mean()\n",
    "\n",
    "ordered_performance = final_generation_performance_mean_values.sort_values(ascending=False).index.tolist()\n",
    "\n",
    "combined_performance['metric'] = pd.Categorical(\n",
    "    combined_performance['metric'], categories=ordered_performance, ordered=True\n",
    ")\n",
    "\n",
    "combined_df_performance_melted_sorted = combined_performance.sort_values(by='metric')\n",
    "\n",
    "fig_performance, ax_performance = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=combined_df_performance_melted_sorted,\n",
    "    x='generation',\n",
    "    y='value',\n",
    "    hue='metric',\n",
    "    ax=ax_performance,\n",
    "    estimator='mean',  # Plot the mean value for each metric per generation\n",
    "    errorbar='sd',     # Show the standard deviation as a shaded area\n",
    ")\n",
    "ax_performance.set_title(\"Mean Performance Metrics Over Generations (Aggregated Across Runs)\")\n",
    "ax_performance.set_xlabel(\"Generation\")\n",
    "ax_performance.set_ylabel(\"Mean Value\")\n",
    "\n",
    "handles_perf, labels_perf = ax_performance.get_legend_handles_labels()\n",
    "\n",
    "new_labels_perf = []\n",
    "for label in labels_perf:\n",
    "    # Get the average value at the final generation for this specific metric\n",
    "    mean_value_at_final = final_generation_performance_mean_values.get(label, 'N/A')\n",
    "\n",
    "    if mean_value_at_final == 'N/A':\n",
    "        new_labels_perf.append(f\"{label} (N/A)\") # Handle cases where metric might not be in final_generation_performance_mean_values\n",
    "    else:\n",
    "        new_labels_perf.append(f\"{label} ({mean_value_at_final:.2f})\")\n",
    "\n",
    "# Update the legend with new labels and correct position\n",
    "ax_performance.legend(handles=handles_perf, labels=new_labels_perf, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "fig_performance.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Final Generation performance (mean across runs):\")\n",
    "print(final_generation_performance_mean_values.sort_values(ascending=False).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
